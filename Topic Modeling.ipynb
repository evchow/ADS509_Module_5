{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce2bb89",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 5.1: Topic Modeling\n",
    "\n",
    "This notebook holds Assignment 5.1 for Module 5 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In this assignment you will work with a categorical corpus that accompanies `nltk`. You will build the three types of topic models described in Chapter 8 of _Blueprints for Text Analytics using Python_: NMF, LSA, and LDA. You will compare these models to the true categories. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85bce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "# These libraries may be useful to you\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#import gensim\n",
    "#import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "#from gensim.models import CoherenceModel,LdaMulticore, Phrases \n",
    "#from gensim.models.phrases import Phraser \n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a218df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add any additional libaries you need here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494de237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function comes from the BTAP repo.\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a901c",
   "metadata": {},
   "source": [
    "## Getting to Know the Brown Corpus\n",
    "\n",
    "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457c59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adventure we have 29 articles.\n",
      "For belles_lettres we have 75 articles.\n",
      "For editorial we have 27 articles.\n",
      "For fiction we have 29 articles.\n",
      "For government we have 30 articles.\n",
      "For hobbies we have 36 articles.\n",
      "For humor we have 9 articles.\n",
      "For learned we have 80 articles.\n",
      "For lore we have 48 articles.\n",
      "For mystery we have 24 articles.\n",
      "For news we have 44 articles.\n",
      "For religion we have 17 articles.\n",
      "For reviews we have 17 articles.\n",
      "For romance we have 29 articles.\n",
      "For science_fiction we have 6 articles.\n"
     ]
    }
   ],
   "source": [
    "# categories of articles in Brown corpus\n",
    "for category in brown.categories() :\n",
    "    print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb133c",
   "metadata": {},
   "source": [
    "Let's create a dataframe of the articles in of hobbies, editorial, government, news, and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f50b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['editorial','government','news','romance','hobbies'] \n",
    "\n",
    "category_list = []\n",
    "file_ids = []\n",
    "texts = []\n",
    "\n",
    "for category in categories : \n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "        \n",
    "        # build some lists for a dataframe\n",
    "        category_list.append(category)\n",
    "        file_ids.append(file_id)\n",
    "        \n",
    "        text = brown.words(fileids=file_id)\n",
    "        texts.append(\" \".join(text))\n",
    "\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['category'] = category_list\n",
    "df['id'] = file_ids\n",
    "df['text'] = texts \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586f47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some helpful columns on the df\n",
    "df['char_len'] = df['text'].apply(len)\n",
    "df['word_len'] = df['text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2128fd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAGmCAYAAACp/VpSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjaElEQVR4nO3debxdZX3v8c8XSIkyVIRoKQETbbQMAkKqDAZQW6WDglUU64DXIS1qtVZbp9tCW3P1Or6qXrFUBfRaFGdKtYqoCIrACTIIaAtOpHAxUGuDA4bwu3/sdfAYT5JzTvLsdfY5n/frtV9772ettfdvZycn37OeZz1PqgpJkiS1s13fBUiSJM11Bi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqbIe+C9iSPfbYo5YsWdJ3GZIkSVu0evXq26pq0cbtWwxcSfYG3gf8GnA3cHpV/X2SU4HnA2u7XV9dVZ/qjnkV8FxgA/DiqvpM134ocCZwL+BTwEtqCxOBLVmyhLGxsal8RkmSpF4l+e5k7VM5w3UX8LKquiLJLsDqJOd3295aVW/a6I32A04E9gd+HfhckgdX1QbgNGAl8FUGgetY4NMz+UCSJEmjYotjuKrqlqq6onu8Drge2GszhxwHfLCq7qyqbwM3AA9Psiewa1Vd0p3Veh9w/NZ+AEmSpNluWoPmkywBHgZc2jW9KMnVSd6bZLeubS/gpgmHrena9uoeb9w+2fusTDKWZGzt2rWT7SJJkjQypjxoPsnOwEeBP6uq/05yGvB3QHX3bwaeA2SSw2sz7b/cWHU6cDrA8uXLf2mf9evXs2bNGn76059OtXxNsHDhQhYvXsyCBQv6LkWSpHlhSoEryQIGYesDVfUxgKq6dcL2fwTO656uAfaecPhi4OauffEk7dO2Zs0adtllF5YsWUIyWY7TplQVt99+O2vWrGHp0qV9lyNJ0rywxS7FDBLNe4Drq+otE9r3nLDbE4Gvd4/PBU5MsmOSpcAy4LKqugVYl+Sw7jWfBXxyJkX/9Kc/ZffddzdszUASdt99d88OSpI0RFM5w3Uk8EzgmiRXdm2vBp6W5GAG3YLfAf4YoKquTXIOcB2DKxxf2F2hCHAyP58W4tNsxRWKhq2Z889OkqTh2mLgqqqLmXz81ac2c8wqYNUk7WPAAdMpUJIkadTN+pnmp2LJK/9lm77ed17/+9v09abizDPPZGxsjHe84x2Tbj/11FPZeeedefnLXz7kyiRJ0tZyLcWebNiwYcs7SZKkOcHANQNveMMbeNvb3gbAS1/6Uh796EcDcMEFF/CMZzyDs88+m4c+9KEccMABvOIVr7jnuJ133pm//uu/5hGPeASXXHIJZ5xxBg9+8IM5+uij+fKXvzzl97/xxhs59thjOfTQQ1mxYgXf+MY3AHj2s5/Ni1/8Yo444gge+MAH8pGPfGQbfmpJkjRTBq4ZOOqoo7jooosAGBsb44477mD9+vVcfPHFLFu2jFe84hV8/vOf58orr+Tyyy/nE5/4BAA/+tGPOOCAA7j00kt50IMexCmnnMKXv/xlzj//fK677ropv//KlSt5+9vfzurVq3nTm97EC17wgnu23XLLLVx88cWcd955vPKVr9ymn1uSJM3MnBjDNWyHHnooq1evZt26dey4444ccsghjI2NcdFFF/H4xz+eY445hkWLBguFP/3pT+dLX/oSxx9/PNtvvz1PetKTALj00kt/Yb+nPvWp/Nu//dsW3/uOO+7gK1/5CieccMI9bXfeeec9j48//ni222479ttvP2699dbJXkKSJA2ZgWsGFixYwJIlSzjjjDM44ogjOPDAA/nCF77AjTfeyD777MPq1asnPW7hwoVsv/329zyfyfQMd999N/e5z3248sorJ92+44473vN4sGSlJEmbtq0vPJtt+rgQbjJ2Kc7QUUcdxZve9CaOOuooVqxYwbve9S4OPvhgDjvsMC688EJuu+02NmzYwNlnn83RRx/9S8c/4hGP4Itf/CK3334769ev58Mf/vCU3nfXXXdl6dKl9+xfVVx11VXb9LNJkqRta06c4eojva5YsYJVq1Zx+OGHs9NOO7Fw4UJWrFjBnnvuyete9zoe9ahHUVX83u/9Hscdd9wvHb/nnnty6qmncvjhh7PnnntyyCGHTPnKxQ984AOcfPLJvPa1r2X9+vWceOKJHHTQQdv6I0qSpG0ks73bafny5TU2NvYLbddffz377rtvTxXNDf4ZSpLALsVtLcnqqlq+cbtdipIkSY3NiS7FuWTVqlW/NJ7rhBNO4DWveU1PFUmSpK1l4JplXvOa1xiuJEmaY0a2S3G2jz2bzfyzkyRpuEYycC1cuJDbb7/d4DADVcXtt9/OwoUL+y5FkqR5YyS7FBcvXsyaNWtYu3Zt36WMpIULF7J48eK+y5Akad4YycC1YMECli5d2ncZmmW8tFmSNFuNZJeiJEnSKDFwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMjOS2EpLnHaT1Gl9+dtGUGro3M5R8c/tCQJKkfdilKkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjW0xcCXZO8kXklyf5NokL+na75vk/CT/3t3vNuGYVyW5Ick3kzxuQvuhSa7ptr0tSdp8LEmSpNljKme47gJeVlX7AocBL0yyH/BK4IKqWgZc0D2n23YisD9wLPDOJNt3r3UasBJY1t2O3YafRZIkaVbaYuCqqluq6oru8TrgemAv4DjgrG63s4Dju8fHAR+sqjur6tvADcDDk+wJ7FpVl1RVAe+bcIwkSdKcNa0xXEmWAA8DLgXuX1W3wCCUAffrdtsLuGnCYWu6tr26xxu3S5IkzWlTDlxJdgY+CvxZVf335nadpK020z7Ze61MMpZkbO3atVMtUZIkaVaaUuBKsoBB2PpAVX2sa7616yaku/9+174G2HvC4YuBm7v2xZO0/5KqOr2qllfV8kWLFk31s0iSJM1KU7lKMcB7gOur6i0TNp0LnNQ9Pgn45IT2E5PsmGQpg8Hxl3XdjuuSHNa95rMmHCNJkjRn7TCFfY4Englck+TKru3VwOuBc5I8F/gecAJAVV2b5BzgOgZXOL6wqjZ0x50MnAncC/h0d5MkSZrTthi4qupiJh9/BfCYTRyzClg1SfsYcMB0CpQkSRp1zjQvSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNbbFwJXkvUm+n+TrE9pOTfIfSa7sbr83YdurktyQ5JtJHjeh/dAk13Tb3pYk2/7jSJIkzT5TOcN1JnDsJO1vraqDu9unAJLsB5wI7N8d884k23f7nwasBJZ1t8leU5Ikac7ZYuCqqi8B/znF1zsO+GBV3VlV3wZuAB6eZE9g16q6pKoKeB9w/AxrliRJGilbM4brRUmu7rocd+va9gJumrDPmq5tr+7xxu2SJElz3kwD12nAg4CDgVuAN3ftk43Lqs20TyrJyiRjScbWrl07wxIlSZJmhxkFrqq6tao2VNXdwD8CD+82rQH2nrDrYuDmrn3xJO2bev3Tq2p5VS1ftGjRTEqUJEmaNWYUuLoxWeOeCIxfwXgucGKSHZMsZTA4/rKqugVYl+Sw7urEZwGf3Iq6JUmSRsYOW9ohydnAMcAeSdYApwDHJDmYQbfgd4A/Bqiqa5OcA1wH3AW8sKo2dC91MoMrHu8FfLq7SZIkzXlbDFxV9bRJmt+zmf1XAasmaR8DDphWdZIkSXOAM81LkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGtti4Ery3iTfT/L1CW33TXJ+kn/v7nebsO1VSW5I8s0kj5vQfmiSa7ptb0uSbf9xJEmSZp+pnOE6Ezh2o7ZXAhdU1TLggu45SfYDTgT27455Z5Ltu2NOA1YCy7rbxq8pSZI0J20xcFXVl4D/3Kj5OOCs7vFZwPET2j9YVXdW1beBG4CHJ9kT2LWqLqmqAt434RhJkqQ5baZjuO5fVbcAdPf369r3Am6asN+arm2v7vHG7ZNKsjLJWJKxtWvXzrBESZKk2WFbD5qfbFxWbaZ9UlV1elUtr6rlixYt2mbFSZIk9WGmgevWrpuQ7v77XfsaYO8J+y0Gbu7aF0/SLkmSNOfNNHCdC5zUPT4J+OSE9hOT7JhkKYPB8Zd13Y7rkhzWXZ34rAnHSJIkzWk7bGmHJGcDxwB7JFkDnAK8HjgnyXOB7wEnAFTVtUnOAa4D7gJeWFUbupc6mcEVj/cCPt3dJEmS5rwtBq6qetomNj1mE/uvAlZN0j4GHDCt6iRJkuYAZ5qXJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGtuqwJXkO0muSXJlkrGu7b5Jzk/y7939bhP2f1WSG5J8M8njtrZ4SZKkUbAtznA9qqoOrqrl3fNXAhdU1TLggu45SfYDTgT2B44F3plk+23w/pIkSbNaiy7F44CzusdnAcdPaP9gVd1ZVd8GbgAe3uD9JUmSZpWtDVwFfDbJ6iQru7b7V9UtAN39/br2vYCbJhy7pmuTJEma03bYyuOPrKqbk9wPOD/JNzazbyZpq0l3HIS3lQD77LPPVpYoSZLUr606w1VVN3f33wc+zqCL8NYkewJ099/vdl8D7D3h8MXAzZt43dOranlVLV+0aNHWlChJktS7GQeuJDsl2WX8MfBY4OvAucBJ3W4nAZ/sHp8LnJhkxyRLgWXAZTN9f0mSpFGxNV2K9wc+nmT8df6pqv41yeXAOUmeC3wPOAGgqq5Ncg5wHXAX8MKq2rBV1UuSJI2AGQeuqvoWcNAk7bcDj9nEMauAVTN9T0mSpFHkTPOSJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSY0MPXEmOTfLNJDckeeWw31+SJGnYhhq4kmwP/B/gd4H9gKcl2W+YNUiSJA3bsM9wPRy4oaq+VVU/Az4IHDfkGiRJkoZq2IFrL+CmCc/XdG2SJElzVqpqeG+WnAA8rqqe1z1/JvDwqvrTjfZbCazsnj4E+ObQihy+PYDb+i5CM+J3N9r8/kaX391om+vf3wOqatHGjTsMuYg1wN4Tni8Gbt54p6o6HTh9WEX1KclYVS3vuw5Nn9/daPP7G11+d6Ntvn5/w+5SvBxYlmRpkl8BTgTOHXINkiRJQzXUM1xVdVeSFwGfAbYH3ltV1w6zBkmSpGEbdpciVfUp4FPDft9ZbF50nc5Rfnejze9vdPndjbZ5+f0NddC8JEnSfOTSPpIkSY0ZuCRJkhozcEmSJDVm4JKmIclLptKm2SnJkUl26h4/I8lbkjyg77q0ZUl2SrJd9/jBSZ6QZEHfdWl6xv/9zUcOmh+SJH+4ue1V9bFh1aKZS3JFVR2yUdvXquphfdWkqUtyNXAQcCDwfuA9wB9W1dG9FqYtSrIaWAHsBnwVGAN+XFVP77UwTUmSI4B3AztX1T5JDgL+uKpe0HNpQzP0aSHmscdvZlsBBq5ZLMnTgD8CliaZOFnvLsDt/VSlGbirqirJccDfV9V7kpzUd1GaklTVj5M8F3h7Vb0hydf6LkpT9lbgcXSTnVfVVUmO6rek4TJwDUlV/Y++a9BW+QpwC4M1wN48oX0dcHUvFWkm1iV5FfBMYEWS7QG7pUZDkhwOPB14btfm/2EjpKpuSjKxaUNftfTBv6w9SPL7wP7AwvG2qvrb/irSllTVd4HvAof3XYu2ylMZnKl8TlX9vyT7AG/suSZNzUuAVwEfr6prkzwQ+ELPNWnqbuq6Fatb2u/FwPU91zRUjuEasiTvAu4NPIpBf/aTgcuq6rmbPVCzQjcW738D9wPS3aqqdu21ME1ZN0h+WVV9Lsm9ge2ral3fdWnzkjywqr7Vdx2amSR7AH8P/DaDn5ufBV5SVfNmSIaBa8iSXF1VB0643xn4WFU9tu/atGVJbgAeX1Xz6jezuSLJ84GVwH2r6kFJlgHvqqrH9FyatiDJl4C9gMuBLwEXVdU1/VYlTZ3TQgzfT7r7Hyf5dWA9sLTHejQ9txq2RtoLgSOB/waoqn9ncLZSs1xVHQXsC7ydwZWK/5LkP/utSlOV5Kwk95nwfLck7+2xpKFzDNfwndf9pXsjcAWDKxTf3WtFmo6xJB8CPgHcOd7otB4j486q+tn4wN0kOzD4N6hZLskjGUwLsQK4D3AecFGfNWlaDqyq/xp/UlU/SDKvptMxcA1ZVf1d9/CjSc4DFlbVD/usSdOyK/BjYGIXsNN6jI4Lk7wauFeS3wFeAPxzzzVpai5kMPfW64BPVdXPeq5H07Ndkt2q6gcASe7LPMsgjuEakiSPrqrPb2oCVM+QSO11M5U/l0FgDvAZ4N3lD8JZr+sZOBI4Cvgt4G7gkqr6qz7r0tQkeRaDq0w/0jWdAKyqqvf3V9VwGbiGJMnfVNUpSc6YZHNV1XOGXpSmLcmDgdOA+1fVAUkOBJ5QVa/tuTRpzkuyL3A0g27FI4DvuUrA6EiyP4Mr9ANcUFXX9VzSUBm4hqj77frJVXVO37VoZpJcCPwF8A/jy/kk+XpVHdBvZdqcJOdU1VOSXMMkY7aq6sAeytI0JLkR+CZwMYOxW5farThauomG78+ErsSq+l5/FQ3XvOo/7VtV3Z3kRYCBa3Tdu6ou22i25Lv6KkZTNr7A+B/0WoW2xrKqurvvIjQzSf4UOAW4lcEM82Hwy8+8+WXHaSGG7/wkL0+yd5L7jt/6LkpTdluSB9GdJUnyZAZL/mgWq6pbuvvvMri6dHwB6zu7Ns1+v5HkgiRfB0hyYJL/2XdRmrKXAA+pqv2r6sCqeuh8O7Nsl+KQJfn2JM1VVQ8cejGatm45kdMZjB/5AfBt4BlV9Z0+69LUJHke8NfA5xn8hn008LdVNa/mAxpFduePtiRfAH6nquZtj4BdikNWVU5yOsK6pUV+O8lOwHYuCTNy/gJ42PhyIkl2Z7AwuYFr9rM7f7R9C/hikn/hF+cwfEt/JQ2XgWvIkiwATmZwaTPAFxn8xra+t6I0Zd2l6c8ClgA7jP/wr6oX91eVpmENMDEkrwNu6qkWTY/d+aPte93tV7rbvGOX4pAleTewADira3omsKGqntdfVZqqJF8Bvgpcw2AeIACq6qxNHqTeJfnz7uHBwEOBTzL4j/s4BovH/0lPpWmKNtGd/3TH4GlUGLiGLMlVVXXQlto0OyW5oqoO6bsOTU+SUza3var+Zli1aGaS7Ag8mcHZ5fsyWA+zqupv+6xLU5NkEfCXwP7AwvH2qnp0b0UNmV2Kw7chyYOq6ka457e2DT3XpKl7f5LnM1jHbeI4BBfRncU2DlRJdh00OwZvhHwS+C8Ga9De3G8pmoEPAB9iMDXLnwAnAWt7rWjIPMM1ZEkeA5zBYABhgAcAz6mqz/damKYkyQuBVQx+8I//4/Eq0xGRZDmDf3+7dE0/ZPDvb3V/VWkqvCJxtCVZXVWHJrl6fDqIJBfOp5UCPMM1fBcDy4CHMAhc3+i3HE3TnwO/UVW39V2IZuS9wAuq6iKAJI9kEMDm1XxAI+orSR5aVdf0XYhmZPzCsFuS/D6Ds5SLe6xn6Axcw3dJNwbo6vGGJFcAjgsaDdcCP+67CM3YuvGwBVBVFyexW3E0PBJ4djeX4Z10M5XPt8kzR9hrk/wq8DLg7cCuwEv7LWm4DFxDkuTXgL2AeyV5GIMfFjD4S3fv3grTdG0Aruwm8Zs4hstpIWaxJOO/0FyW5B+Asxl0CT+VwdQsmv1+t+8CNHNVdV738IcMFrCedxzDNSRJTgKeDSwHxiZsWgecWVUf66MuTU/3Pf4Sp4WY3bqAvCk1n66UkvqQZCnwp3RzGI63V9UT+qpp2AxcQ5bkSVX10b7rkCRpWJJcBbyHX57D8MLeihoyA9eQJHlGVf3fJC/j51e33WM+LW8wypIcCZzK4OrSHfj5OBKvUhwB3RiSU/j5Sg8XMlhL8Yf9VSXNfUkurapH9F1HnxzDNTw7dfc791qFttZ7GAz0XI3zp42i9wJfB57SPX8mg6sU/7C3iqT54e+7CYg/yy+Of72iv5KGyzNc0jT4W9poS3JlVR28pTZJ21aS1zH4BedGft6lOK/GT3qGa0iSvG1z273KbWR8IckbgY8xT39LG3E/SfLIqroY7uki/knPNUnzwROBB1bVz/oupC8GruEZn8n6SGA/BkscAJwwYZtmv/GzW8sntBUwb35LG3EnA2d1Y7lgsAjypFeeStqmrgLuA3y/5zp6Y5fikHWXpz+2qtZ3zxcAn62qeTkvyShJsj3w4qp6a9+1aGYmLID8IAY//H+ICyBLzSX5IoMVHS7nF3sH5s20EJ7hGr5fZ7CO2/hixzt3bZrlqmpDkicABq7RNXEB5P/otxRpXjml7wL6ZuAavtcDV3RpH+BoBtMMaDR8Jck7GHQJ/2i80TFcI2NxVR3bdxHSfFNVFya5P/BbXdNlVTWvuhftUhyyJGFwpcafMQhaVwK/VlWX9VeVpmoTM5bPqyttRlmS04G3uwCyNFxJngK8kcFSWgFWAH9RVR/ps65hMnANWZLTGFwS++iq2jfJbgzGcP3WFg6VNENJrmFwccMOwDLgW7gAsjQ03UzzvzN+VivJIuBzVXVQv5UNj12Kw/eIqjokydcAquoHSX6l76I0Nd0p8f8F/HpV/W6S/YDDq+o9PZemzfuDvguQ5rntNupCvB3Yrq9i+mDgGr713dVuBfek/Ls3f4hmkTMZzEz+mu75vzEYz2XgmsWq6rt91yDNV91QmsuTfAY4u2t+KvCp/qoavnmVLmeJtwEfB+6XZBVwMYMzJhoNe1TVOXQhuaruwiV+JGmTajB26WDgHxhMDXEQcHpVvaLPuobNM1xDVlUfSLIaeAyD8SPHV9X1PZelqftRkt35+RnKwxjM5SRJ2rRLgJuq6s/7LqQvDpqXpiHJoQzOUh7AYBHkRcCTq+rqXguTpFksyXXAg4Hv8otT6sybC1YMXNI0JdkBeAiDM5TfHF81QJI0uSQPmKx9Po2vNHBJ09Bd2vwh4ENVdWPf9UiSRoOD5qXpeQJwF3BOksuTvDzJPn0XJUma3TzDJc1QkmXAXwFPr6rt+65HkjR7eZWiNE1JlgBPYTCPzAbgL3stSJI06xm4pGlIcimwAPgwcEJVfavnkiRJI8AuRWkakvxmVX2j7zokSaPFQfPS9NyS5C1Jxrrbm5P8at9FSZJmNwOXND3vBdYxGMP1FOC/GaytKEnSJtmlKE1Dkiur6uAttUmSNJFnuKTp+UmSR44/SXIk8JMe65EkjQDPcEnTkOQg4H3A+LitHwAnuZaiJGlzDFzSNCQZX+l+5+7+DuCHwOqqurKXoiRJs55ditL0LAf+BNiVwVmulcAxwD8mcQJUSdKkPMMlTUOSzwBPqqo7uuc7Ax8BnsjgLNd+fdYnSZqdPMMlTc8+wM8mPF8PPKCqfgLc2U9JkqTZzqV9pOn5J+CrST7ZPX88cHaSnYDr+itLkjSb2aUoTVOSQ4FHAgEurqqxnkuSJM1yBi5JkqTGHMMlSZLUmIFLkiSpMQOXpDkjyTFJjui7DknamIFL0lxyDNA0cGXAn52SpsUfGpJmvSTPSnJ1kquSvD/J45NcmuRrST6X5P5JljBYBeClSa5MsiLJoiQfTXJ5dzuye71FSc5PckWSf0jy3SR7dNv+PMnXu9ufdW1Lklyf5J3AFcBfJXnrhPqen+Qtw/5zkTQ6vEpR0qyWZH/gY8CRVXVbkvsCBfxXVVWS5wH7VtXLkpwK3FFVb+qO/SfgnVV1cZJ9gM9U1b5J3gH8R1W9LsmxwKeBRcADgDOBwxhM+3Ep8AwGi5R/Cziiqr7azbt2NfCbVbU+yVeAP66qa4b0xyJpxDjxqaTZ7tHAR6rqNoCq+s8kDwU+lGRP4FeAb2/i2N8G9ksy/nzXJLswmEftid3r/WuSH3TbHwl8vKp+BJDkY8AK4Fzgu1X11e6YHyX5PPAHSa4HFhi2JG2OgUvSbBcGZ7Qmejvwlqo6N8kxwKmbOHY74PBu6aWfv+CEBDbJe23KjzZ6/m7g1cA3gDM2c5wkOYZL0qx3AfCUJLsDdF2Kvwr8R7f9pAn7rgN2mfD8s8CLxp8kObh7eDHwlK7tscBuXfuXgOOT3LvrNnwicNFkRVXVpcDewB8BZ8/ws0maJwxckma1qroWWAVcmOQq4C0Mzmh9OMlFwG0Tdv9n4Injg+aBFwPLuwH31zEYVA/wN8Bjk1wB/C5wC7Cuqq5gMIbrMgbjt95dVV/bTHnnAF+uqh9sZh9JctC8pPknyY7Ahqq6K8nhwGlVdfAMXuc84K1VdcG2rlHS3OIYLknz0T7AOd18Wj8Dnj+dg5Pch8FZsKsMW5KmwjNckiRJjTmGS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDX2/wHflILkywuvqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.groupby('category').agg({'word_len': 'mean'}).plot.bar(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ffeb5",
   "metadata": {},
   "source": [
    "Now do our TF-IDF and Count vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a7d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df[\"text\"])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875deba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1062b21",
   "metadata": {},
   "source": [
    "Q: What do the two data frames `count_text_vectors` and `tfidf_text_vectors` hold? \n",
    "\n",
    "A: Both dataframes hold a matrix of tokens. They both have a minimum threshold of 5 document appearances, and ignore words that appear in more than 70% of documents. More specifically, count_text_vectors is a matrix of vectors that represent number of article appearances. tfidf_text_vectors is a matrix of vectors that represent TF-IDF scores for each word.\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html and \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html and \n",
    "https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c3f94",
   "metadata": {},
   "source": [
    "## Fitting a Non-Negative Matrix Factorization Model\n",
    "\n",
    "In this section the code to fit a five-topic NMF model has already been written. This code comes directly from the [BTAP repo](https://github.com/blueprints-for-text-analytics-python/blueprints-text), which will help you tremendously in the coming sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28745a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "nmf_text_model = NMF(n_components=5, random_state=314)\n",
    "# some notes taken from Professor Marbut via Slack\n",
    "# W will provide a list of probabilities that a document falls under a specific topic\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67185e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  mr (0.51)\n",
      "  president (0.45)\n",
      "  kennedy (0.43)\n",
      "  united (0.42)\n",
      "  khrushchev (0.40)\n",
      "\n",
      "Topic 01\n",
      "  said (0.88)\n",
      "  didn (0.46)\n",
      "  ll (0.45)\n",
      "  thought (0.42)\n",
      "  man (0.37)\n",
      "\n",
      "Topic 02\n",
      "  state (0.40)\n",
      "  development (0.36)\n",
      "  tax (0.33)\n",
      "  sales (0.30)\n",
      "  program (0.25)\n",
      "\n",
      "Topic 03\n",
      "  mrs (2.61)\n",
      "  mr (0.78)\n",
      "  said (0.64)\n",
      "  miss (0.52)\n",
      "  car (0.51)\n",
      "\n",
      "Topic 04\n",
      "  game (1.01)\n",
      "  league (0.74)\n",
      "  ball (0.72)\n",
      "  baseball (0.71)\n",
      "  team (0.66)\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee51e9b",
   "metadata": {},
   "source": [
    "Now some work for you to do. Compare the NMF factorization to the original categories from the Brown Corpus.\n",
    "\n",
    "We are interested in the extent to which our NMF factorization agrees or disagrees with the original categories in the corpus. For each topic in your NMF model, tally the Brown categories and interpret the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8c8eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>char_len</th>\n",
       "      <th>word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb01</td>\n",
       "      <td>Assembly session brought much good The General...</td>\n",
       "      <td>12659</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb02</td>\n",
       "      <td>Must Berlin remain divided ? ? The inference h...</td>\n",
       "      <td>12544</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb03</td>\n",
       "      <td>A good man departs . Goodby , Mr. Sam . Sam Ra...</td>\n",
       "      <td>11871</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb04</td>\n",
       "      <td>A shock wave from Africa Word of Dag Hammarskj...</td>\n",
       "      <td>12284</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb05</td>\n",
       "      <td>Help when needed If the Dominican Republic ach...</td>\n",
       "      <td>12479</td>\n",
       "      <td>2241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category    id                                               text  \\\n",
       "0  editorial  cb01  Assembly session brought much good The General...   \n",
       "1  editorial  cb02  Must Berlin remain divided ? ? The inference h...   \n",
       "2  editorial  cb03  A good man departs . Goodby , Mr. Sam . Sam Ra...   \n",
       "3  editorial  cb04  A shock wave from Africa Word of Dag Hammarskj...   \n",
       "4  editorial  cb05  Help when needed If the Dominican Republic ach...   \n",
       "\n",
       "   char_len  word_len  \n",
       "0     12659      2200  \n",
       "1     12544      2234  \n",
       "2     11871      2244  \n",
       "3     12284      2230  \n",
       "4     12479      2241  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# for reference/clarity (taken from Slack discussion): \n",
    "# 1) W_text_matrix is used to determine highest probability topic per document then \n",
    "# 2) display the topic-document relationship however you'd like\n",
    "\n",
    "# let's take a quick look at the brown data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "145c8988-a3d3-45a3-8502-ce8f483d5819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news          44\n",
       "hobbies       36\n",
       "government    30\n",
       "romance       29\n",
       "editorial     27\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how the brown corpus has the categories distributed\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6864f75-56a2-41ed-bbae-d24b1f9c0691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.321769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.040403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200523</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.111485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3         4\n",
       "0  0.168337  0.000000  0.196650  0.0  0.028598\n",
       "1  0.321769  0.000000  0.000000  0.0  0.000000\n",
       "2  0.273861  0.040403  0.000000  0.0  0.001421\n",
       "3  0.270374  0.000000  0.048464  0.0  0.000345\n",
       "4  0.200523  0.002224  0.111485  0.0  0.017609"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's take a look at W_test_matrix\n",
    "W_text_matrix_df = pd.DataFrame(W_text_matrix)\n",
    "W_text_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14aba6e7-6567-4112-9f9f-39decd8b6b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 00</th>\n",
       "      <th>Topic 01</th>\n",
       "      <th>Topic 02</th>\n",
       "      <th>Topic 03</th>\n",
       "      <th>Topic 04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.321769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.040403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200523</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.111485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic 00  Topic 01  Topic 02  Topic 03  Topic 04\n",
       "0  0.168337  0.000000  0.196650       0.0  0.028598\n",
       "1  0.321769  0.000000  0.000000       0.0  0.000000\n",
       "2  0.273861  0.040403  0.000000       0.0  0.001421\n",
       "3  0.270374  0.000000  0.048464       0.0  0.000345\n",
       "4  0.200523  0.002224  0.111485       0.0  0.017609"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each observation corresponds to the probability of that article (row) belonging\n",
    "# to a certain topic (column)\n",
    "# for consistency, we'll rename the columns to match\n",
    "W_text_matrix_df.columns = ['Topic 00', 'Topic 01', 'Topic 02', 'Topic 03', 'Topic 04']\n",
    "W_text_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "981b6d43-ba85-4105-accf-5522840c4b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>char_len</th>\n",
       "      <th>word_len</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb01</td>\n",
       "      <td>Assembly session brought much good The General...</td>\n",
       "      <td>12659</td>\n",
       "      <td>2200</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb02</td>\n",
       "      <td>Must Berlin remain divided ? ? The inference h...</td>\n",
       "      <td>12544</td>\n",
       "      <td>2234</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb03</td>\n",
       "      <td>A good man departs . Goodby , Mr. Sam . Sam Ra...</td>\n",
       "      <td>11871</td>\n",
       "      <td>2244</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb04</td>\n",
       "      <td>A shock wave from Africa Word of Dag Hammarskj...</td>\n",
       "      <td>12284</td>\n",
       "      <td>2230</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>editorial</td>\n",
       "      <td>cb05</td>\n",
       "      <td>Help when needed If the Dominican Republic ach...</td>\n",
       "      <td>12479</td>\n",
       "      <td>2241</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category    id                                               text  \\\n",
       "0  editorial  cb01  Assembly session brought much good The General...   \n",
       "1  editorial  cb02  Must Berlin remain divided ? ? The inference h...   \n",
       "2  editorial  cb03  A good man departs . Goodby , Mr. Sam . Sam Ra...   \n",
       "3  editorial  cb04  A shock wave from Africa Word of Dag Hammarskj...   \n",
       "4  editorial  cb05  Help when needed If the Dominican Republic ach...   \n",
       "\n",
       "   char_len  word_len     topic  \n",
       "0     12659      2200  Topic 02  \n",
       "1     12544      2234  Topic 00  \n",
       "2     11871      2244  Topic 00  \n",
       "3     12284      2230  Topic 00  \n",
       "4     12479      2241  Topic 00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's add a column in the brown corpus identifying the topic with the highest probability\n",
    "# see https://stackoverflow.com/questions/29919306/find-the-column-name-which-has-the-maximum-value-for-each-row \n",
    "# for reference for cleaner code\n",
    "df['topic'] = W_text_matrix_df.idxmax(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a933b64-557f-4b89-8e43-c14e47627f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category     topic\n",
       "0  editorial  Topic 02\n",
       "1  editorial  Topic 00\n",
       "2  editorial  Topic 00\n",
       "3  editorial  Topic 00\n",
       "4  editorial  Topic 00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's isolate our variables of interest\n",
    "df2 = df[['category', 'topic']].copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c956e6b5-f486-4134-a9b1-fee1c2c35a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic</th>\n",
       "      <th>Topic 00</th>\n",
       "      <th>Topic 01</th>\n",
       "      <th>Topic 02</th>\n",
       "      <th>Topic 03</th>\n",
       "      <th>Topic 04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>editorial</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hobbies</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topic       Topic 00  Topic 01  Topic 02  Topic 03  Topic 04\n",
       "category                                                    \n",
       "editorial       20.0       4.0       2.0       NaN       1.0\n",
       "government       4.0       NaN      26.0       NaN       NaN\n",
       "hobbies          NaN       8.0      26.0       1.0       1.0\n",
       "news             8.0       NaN      11.0      17.0       8.0\n",
       "romance          NaN      29.0       NaN       NaN       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use dataframe.pivot_table to see category vs topic distribution\n",
    "# aggfunc = len will count the topics\n",
    "# see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html\n",
    "df_pivot = df2.pivot_table(index='category', columns=['topic'], aggfunc=len)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4e2bc",
   "metadata": {},
   "source": [
    "Q: How does your five-topic NMF model compare to the original Brown categories? \n",
    "\n",
    "A: Compared to the original Brown categories, it appears that Topic 00 with keywords such as \"mr\", \"president\", and \"kennedy\" contains articles classified largely as editorials, followed by news and government respectively. This appears to align well with the Brown category, as the keywords appear affiliated with politics.\n",
    "\n",
    "Topic 01 with keywords such as \"said\", \"thought\", and \"man\" contains articles classified largely as romance. This is followed by hobbies and editorials respectively. Assuming that the keywords allude to opinion pieces, perhaps tabloids and gossip columns, then the categorization of this topic largely as romance seems fitting.\n",
    "\n",
    "Topic 02 with keywords such as \"state\", \"development\", \"sales\", \"program\", and \"tax\" contains articles classified evenly as government and hobbies. This is followed by classifications as news and editorial. A larger amount of articles appear to fall under Topic 02, accounting for nearly a third of all article topics.\n",
    "\n",
    "Topic 03 with keywords such as \"mrs\", \"mr\", \"said\", and \"miss\" contains articles almost unanimously categorized as news except for the one article categorized as hobbies. This may be related to the usage of more formal address of individuals in news.\n",
    "\n",
    "Topic 04 with keywords such as \"game\", \"league\", and \"ball\" is the least popular topic with only ten total articles classified under Topic 04. Of these ten, eight were of the news category, and editorial and hobbies had one article each. The keywords appear to be related to sports, so the categorization and topic distribution may be related to how a sports article is written.\n",
    "\n",
    "Overall, the first three topics have a majority of the articles classified under them, with Topic 03 and 04 underrepresented when compared to the categorization in the original Brown categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e37cb5",
   "metadata": {},
   "source": [
    "## Fitting an LSA Model\n",
    "\n",
    "In this section, follow the example from the repository and fit an LSA model (called a \"TruncatedSVD\" in `sklearn`). Again fit a five-topic model and compare it to the actual categories in the Brown corpus. Use the TF-IDF vectors for your fit, as above. \n",
    "\n",
    "To be explicit, we are once again interested in the extent to which this LSA factorization agrees or disagrees with the original categories in the corpus. For each topic in your model, tally the Brown categories and interpret the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00b53d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# code taken largely from the BTAP repo\n",
    "# we'll be using tfidf_text_vectors that was previously defined\n",
    "# from the BTAP repo, we've updated n_components = 5 to stay consistent\n",
    "svd_text_model = TruncatedSVD(n_components = 5, random_state=314)\n",
    "W_svd_text_matrix = svd_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_svd_text_matrix = svd_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29134d06-0836-4c48-890c-ca61b6d26c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category     topic\n",
       "0  editorial  Topic 00\n",
       "1  editorial  Topic 00\n",
       "2  editorial  Topic 00\n",
       "3  editorial  Topic 00\n",
       "4  editorial  Topic 00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use the W_svd_text_matrix to classify the topics of an article\n",
    "# first, let's put the matrix into a dataframe\n",
    "W_svd_text_matrix_df = pd.DataFrame(W_svd_text_matrix)\n",
    "\n",
    "# we'll define the columns as topics\n",
    "W_svd_text_matrix_df.columns = ['Topic 00', 'Topic 01', 'Topic 02', 'Topic 03', 'Topic 04']\n",
    "\n",
    "# let's define our svd dataframe and add our topic classification\n",
    "df3 = df[['category']].copy()\n",
    "# once again, see # see https://stackoverflow.com/questions/29919306/find-the-column-name-which-has-the-maximum-value-for-each-row \n",
    "# for reference of dataframe.idmax usage\n",
    "df3['topic'] = W_svd_text_matrix_df.idxmax(axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35e6dac1-fcbc-4ca9-8dd2-7aa7ce19070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic</th>\n",
       "      <th>Topic 00</th>\n",
       "      <th>Topic 01</th>\n",
       "      <th>Topic 03</th>\n",
       "      <th>Topic 04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>editorial</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hobbies</th>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topic       Topic 00  Topic 01  Topic 03  Topic 04\n",
       "category                                          \n",
       "editorial       27.0       NaN       NaN       NaN\n",
       "government      30.0       NaN       NaN       NaN\n",
       "hobbies         36.0       NaN       NaN       NaN\n",
       "news            34.0       NaN       3.0       7.0\n",
       "romance         21.0       8.0       NaN       NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use dataframe.pivot_table to see category vs topic distribution\n",
    "# aggfunc = len will count the topics\n",
    "# see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html\n",
    "svd_pivot = df3.pivot_table(index='category', columns=['topic'], aggfunc=len)\n",
    "svd_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94d56f",
   "metadata": {},
   "source": [
    "Q: How does your five-topic LSA model compare to the original Brown categories? \n",
    "\n",
    "A: Where there used to be some distribution of the articles under various topics, the LSA model has categorized the articles largely under Topic 00. Eight articles were classified under Topic 01, seven articles were classified under Topic 04, and only three articles were classified under Topic 03. No articles were classified under Topic 02.\n",
    "\n",
    "Overall, it would appear that the LSA model was not able to classify the articles as well as nearly all of the articles were classified under one category, Topic 00. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "696adf72-798a-4383-a239-708a818b4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (0.44)\n",
      "  mr (0.25)\n",
      "  mrs (0.22)\n",
      "  state (0.20)\n",
      "  man (0.17)\n",
      "\n",
      "Topic 01\n",
      "  said (3.89)\n",
      "  ll (2.73)\n",
      "  didn (2.63)\n",
      "  thought (2.20)\n",
      "  got (1.97)\n",
      "\n",
      "Topic 02\n",
      "  mrs (3.12)\n",
      "  mr (1.70)\n",
      "  said (1.06)\n",
      "  kennedy (0.82)\n",
      "  khrushchev (0.77)\n",
      "\n",
      "Topic 03\n",
      "  mrs (29.45)\n",
      "  club (6.53)\n",
      "  game (6.12)\n",
      "  jr (5.60)\n",
      "  university (5.20)\n",
      "\n",
      "Topic 04\n",
      "  game (4.54)\n",
      "  league (3.27)\n",
      "  baseball (3.22)\n",
      "  ball (3.10)\n",
      "  team (2.94)\n"
     ]
    }
   ],
   "source": [
    "# call display_topics on your model\n",
    "display_topics(svd_text_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b280a",
   "metadata": {},
   "source": [
    "Q: What is your interpretation of the display topics output? \n",
    "\n",
    "A: Compared to NMF, the display topics output for SVD share more keywords between the top five topics. In addition, the percent frequency of the keyword in each topic is distributed in a way that it would be near impossible for articles to be classified under topics other than Topic 00. This is due to the high percent frequency needed for all other topics, which may only occur if the article is not lexically complex or if the article contains a very small number of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4d29",
   "metadata": {},
   "source": [
    "## Fitting an LDA Model\n",
    "\n",
    "Finally, fit a five-topic LDA model using the count vectors (`count_text_vectors` from above). Display the results using `pyLDAvis.display` and describe what you learn from that visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802cb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your LDA model here\n",
    "\n",
    "# once again, this is taken largely from the BTAP repo\n",
    "# n_components has been modified to be consistent with the rest of the notebook, resulting in 5 topics\n",
    "lda_text_model = LatentDirichletAllocation(n_components = 5, random_state=314)\n",
    "W_lda_text_matrix = lda_text_model.fit_transform(count_text_vectors)\n",
    "H_lda_text_matrix = lda_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab18adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (1.05)\n",
      "  mrs (0.82)\n",
      "  little (0.56)\n",
      "  good (0.51)\n",
      "  way (0.50)\n",
      "\n",
      "Topic 01\n",
      "  state (0.67)\n",
      "  development (0.63)\n",
      "  000 (0.57)\n",
      "  program (0.48)\n",
      "  business (0.44)\n",
      "\n",
      "Topic 02\n",
      "  said (1.18)\n",
      "  mr (0.72)\n",
      "  president (0.51)\n",
      "  city (0.43)\n",
      "  state (0.37)\n",
      "\n",
      "Topic 03\n",
      "  feed (0.55)\n",
      "  college (0.54)\n",
      "  general (0.44)\n",
      "  university (0.43)\n",
      "  work (0.37)\n",
      "\n",
      "Topic 04\n",
      "  states (1.14)\n",
      "  state (1.02)\n",
      "  united (0.84)\n",
      "  shall (0.66)\n",
      "  government (0.61)\n"
     ]
    }
   ],
   "source": [
    "# Call `display_topics` on your fitted model here\n",
    "display_topics(lda_text_model, count_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4d63bd-c4c7-410b-bfeb-ccc0a763c268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>editorial</td>\n",
       "      <td>Topic 02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category     topic\n",
       "0  editorial  Topic 02\n",
       "1  editorial  Topic 02\n",
       "2  editorial  Topic 02\n",
       "3  editorial  Topic 02\n",
       "4  editorial  Topic 02"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tallying of brown corpus categories with our LDA model topics to help answer questions\n",
    "\n",
    "# we'll use the W_lda_text_matrix to classify the topics of an article\n",
    "# first, let's put the matrix into a dataframe\n",
    "W_lda_text_matrix_df = pd.DataFrame(W_lda_text_matrix)\n",
    "\n",
    "# we'll define the columns as topics\n",
    "W_lda_text_matrix_df.columns = ['Topic 00', 'Topic 01', 'Topic 02', 'Topic 03', 'Topic 04']\n",
    "\n",
    "# let's define our svd dataframe and add our topic classification\n",
    "df4 = df[['category']].copy()\n",
    "# once again, see # see https://stackoverflow.com/questions/29919306/find-the-column-name-which-has-the-maximum-value-for-each-row \n",
    "# for reference of dataframe.idmax usage\n",
    "df4['topic'] = W_lda_text_matrix_df.idxmax(axis=1)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb853145-fd10-4467-b802-af17fa4323b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic</th>\n",
       "      <th>Topic 00</th>\n",
       "      <th>Topic 01</th>\n",
       "      <th>Topic 02</th>\n",
       "      <th>Topic 03</th>\n",
       "      <th>Topic 04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>editorial</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hobbies</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topic       Topic 00  Topic 01  Topic 02  Topic 03  Topic 04\n",
       "category                                                    \n",
       "editorial        3.0       1.0      21.0       2.0       NaN\n",
       "government       1.0      12.0       3.0       4.0      10.0\n",
       "hobbies         11.0       9.0       2.0       8.0       6.0\n",
       "news             4.0       3.0      32.0       3.0       2.0\n",
       "romance         28.0       NaN       1.0       NaN       NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use dataframe.pivot_table to see category vs topic distribution\n",
    "# aggfunc = len will count the topics\n",
    "# see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html\n",
    "lda_pivot = df4.pivot_table(index='category', columns=['topic'], aggfunc=len)\n",
    "lda_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c67876",
   "metadata": {},
   "source": [
    "Q: What inference do you draw from the displayed topics for your LDA model? \n",
    "\n",
    "A: Looking at the percent frequency of the keywords of each topic, I can assume that LDA will perform better than the LSA model in categorizing the articles under more varied topics. However, looking at the keywords for LDA model topics, there does not appear to be as clear of an explanation for the separation of topics. Compared to NMF, the LDA model may contain a lot of mixing of Brown corpus categories with various LDA model topics.\n",
    "\n",
    "Q: Repeat the tallying of Brown categories within your topics. How does your five-topic LDA model compare to the original Brown categories? \n",
    "\n",
    "A: Our five-topic LDA model has categorized more than half of the articles within Topic 00 and 02, which is a different distribution compared to the fairly even category distribution of the original Brown corpus. Perhaps due to the similar keywords in the topics, aside from the original \"romance\" and \"editorial\" categories of the Brown corpus, the rest of the articles in the original Brown corpus categories have bee nspread amongst the five LDA topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aae75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "lda_display = pyLDAvis.sklearn.prepare(lda_text_model, count_text_vectors, count_text_vectorizer, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a89fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el897891402339169315366125029593\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el897891402339169315366125029593_data = {\"mdsDat\": {\"x\": [-0.24352303362204106, 0.1305571939552594, -0.05665667547392703, 0.041427484839751, 0.12819503030095797], \"y\": [0.006829720679473235, -0.05588474470164648, 0.038523662874467096, -0.11285215230955833, 0.12338351345726453], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [22.89695729653454, 20.431968542841776, 32.00626407252671, 12.3688256129321, 12.29598447516486]}, \"tinfo\": {\"Term\": [\"states\", \"state\", \"said\", \"mrs\", \"united\", \"shall\", \"development\", \"tax\", \"feed\", \"fiscal\", \"college\", \"government\", \"ll\", \"don\", \"000\", \"university\", \"department\", \"didn\", \"sales\", \"president\", \"rhode\", \"got\", \"equipment\", \"little\", \"mother\", \"class\", \"act\", \"program\", \"system\", \"property\", \"hair\", \"baby\", \"clothes\", \"walls\", \"anne\", \"fig\", \"pale\", \"pink\", \"dry\", \"yellow\", \"entrance\", \"hadn\", \"ham\", \"couldn\", \"frames\", \"fingers\", \"flowers\", \"windows\", \"bride\", \"hell\", \"handsome\", \"coat\", \"cloth\", \"sweet\", \"stared\", \"liked\", \"colored\", \"studio\", \"bed\", \"trees\", \"shelter\", \"mother\", \"looked\", \"clay\", \"wasn\", \"guests\", \"didn\", \"woman\", \"sat\", \"pieces\", \"colors\", \"eyes\", \"drill\", \"mrs\", \"ll\", \"don\", \"thought\", \"room\", \"sun\", \"inch\", \"ve\", \"black\", \"little\", \"knew\", \"went\", \"sure\", \"got\", \"door\", \"look\", \"son\", \"know\", \"said\", \"way\", \"come\", \"came\", \"good\", \"place\", \"away\", \"old\", \"water\", \"right\", \"man\", \"let\", \"life\", \"left\", \"house\", \"day\", \"home\", \"systems\", \"marketing\", \"electronic\", \"boats\", \"missiles\", \"components\", \"aircraft\", \"machine\", \"rhode\", \"assessment\", \"shipments\", \"laboratory\", \"bankers\", \"savings\", \"yield\", \"industrial\", \"forests\", \"compared\", \"machines\", \"procurement\", \"missile\", \"conservation\", \"utility\", \"inventories\", \"polaris\", \"manufacturing\", \"machinery\", \"investment\", \"recreation\", \"banks\", \"property\", \"industry\", \"equipment\", \"sales\", \"radiation\", \"planning\", \"development\", \"medical\", \"providence\", \"billion\", \"system\", \"shares\", \"manufacturers\", \"island\", \"1960\", \"production\", \"1959\", \"products\", \"research\", \"co\", \"range\", \"000\", \"program\", \"business\", \"cost\", \"million\", \"available\", \"state\", \"small\", \"company\", \"national\", \"1961\", \"provide\", \"areas\", \"service\", \"use\", \"military\", \"tax\", \"public\", \"khrushchev\", \"player\", \"rayburn\", \"congo\", \"republican\", \"moscow\", \"southern\", \"baseball\", \"railroad\", \"castro\", \"troops\", \"yards\", \"charter\", \"yankees\", \"premier\", \"alexander\", \"democrats\", \"captain\", \"chinese\", \"coach\", \"laos\", \"gen\", \"cuban\", \"opposition\", \"soviet\", \"katanga\", \"republicans\", \"pope\", \"bombs\", \"robinson\", \"berlin\", \"speaker\", \"communist\", \"democratic\", \"eisenhower\", \"league\", \"mayor\", \"cuba\", \"st\", \"police\", \"yesterday\", \"china\", \"west\", \"monday\", \"race\", \"john\", \"east\", \"kennedy\", \"city\", \"mr\", \"meeting\", \"party\", \"president\", \"said\", \"week\", \"war\", \"political\", \"nations\", \"game\", \"committee\", \"leaders\", \"american\", \"world\", \"york\", \"home\", \"county\", \"man\", \"united\", \"people\", \"house\", \"state\", \"day\", \"old\", \"000\", \"government\", \"men\", \"national\", \"states\", \"school\", \"academic\", \"faculty\", \"trustees\", \"campus\", \"recognition\", \"classical\", \"professors\", \"mathematics\", \"musical\", \"tends\", \"feed\", \"stockholders\", \"fulfill\", \"meat\", \"unions\", \"chemical\", \"motors\", \"prosperity\", \"cattle\", \"prestige\", \"designer\", \"curriculum\", \"clerical\", \"catholic\", \"collective\", \"recorded\", \"appearances\", \"creative\", \"membership\", \"trust\", \"music\", \"chamber\", \"students\", \"student\", \"colleges\", \"teachers\", \"college\", \"engineer\", \"interior\", \"university\", \"daily\", \"pool\", \"schools\", \"education\", \"art\", \"general\", \"anti\", \"members\", \"technical\", \"labor\", \"design\", \"administration\", \"level\", \"work\", \"school\", \"president\", \"problem\", \"board\", \"department\", \"american\", \"good\", \"men\", \"aid\", \"world\", \"high\", \"cousin\", \"rehabilitation\", \"coal\", \"vocational\", \"definition\", \"denied\", \"thereof\", \"bonds\", \"payment\", \"rico\", \"puerto\", \"coordination\", \"filing\", \"adopting\", \"recommendation\", \"calendar\", \"hated\", \"proceedings\", \"commodities\", \"sectors\", \"connections\", \"62\", \"vehicles\", \"allocation\", \"treasury\", \"tractor\", \"adjustments\", \"upstairs\", \"shall\", \"assigned\", \"india\", \"exercise\", \"interference\", \"payments\", \"fiscal\", \"authorized\", \"claim\", \"stations\", \"insurance\", \"claims\", \"class\", \"states\", \"income\", \"return\", \"tax\", \"united\", \"junior\", \"hearing\", \"act\", \"countries\", \"cars\", \"state\", \"agreement\", \"department\", \"government\", \"secretary\", \"officer\", \"section\", \"title\", \"federal\", \"use\", \"service\", \"30\", \"board\", \"services\", \"pay\", \"local\", \"day\"], \"Freq\": [328.0, 485.0, 803.0, 307.0, 298.0, 123.0, 199.0, 172.0, 93.0, 107.0, 120.0, 273.0, 167.0, 178.0, 282.0, 122.0, 153.0, 124.0, 117.0, 297.0, 86.0, 147.0, 105.0, 237.0, 97.0, 97.0, 127.0, 230.0, 142.0, 95.0, 35.26603169767948, 35.25985457287084, 32.342823917150476, 32.33880808918393, 34.23407300433101, 31.327619231629416, 26.49851762545449, 25.52477104102501, 23.573236778164105, 25.427138253320564, 21.61942811514905, 30.99304467895145, 19.675700186736563, 51.43981707238502, 20.589733305570025, 17.726312752092973, 23.305040810822835, 16.75197331091849, 17.677966184967996, 15.781789493525478, 15.780666162782088, 15.76503813900025, 14.807347406646526, 14.80685767925678, 14.806525243898374, 14.805562659021428, 15.72134167497508, 14.79303130069053, 34.148748494261184, 27.7424550103045, 57.20416985925252, 90.05985801714512, 78.93387784968832, 75.71076669182483, 53.907238782962956, 29.982839371430053, 108.73073941993056, 50.25085074519484, 34.934191866446334, 48.29752376267048, 27.141746207592842, 83.99183249657624, 31.328311483268067, 234.33243224195706, 134.73682388828428, 142.22532063651963, 113.48998687104921, 84.70739288661433, 47.851073173593385, 58.28164360651531, 69.82209572678236, 54.447334924203105, 159.93873456068246, 71.32903793545293, 100.47914727932297, 70.80739412891513, 101.54763550743206, 56.56434544201614, 89.1493795819194, 57.94278765631495, 112.8022196739492, 300.1915799527015, 143.0821472058164, 108.6678552840921, 97.93192846288196, 146.72016490751113, 107.63695959300955, 81.83857826579674, 125.3325275357801, 93.65427756652943, 105.80662989454602, 122.43392673750746, 76.37882747857952, 81.8560900906336, 81.25833894745288, 87.71132897871966, 85.95109916972224, 84.11085690371317, 37.620339176968784, 41.260430437148145, 26.10850412689408, 38.01490066718644, 22.240995977940408, 21.223514374686555, 54.24848359225264, 50.39470006191909, 82.33814930496457, 17.22632723406695, 13.599502717078893, 16.29088859098537, 10.740632157231778, 17.005387252552133, 15.133342494227248, 72.0384349910599, 14.938223060272144, 24.57436329720797, 28.908173871233394, 17.44886776203955, 36.584742597938266, 7.854789008100239, 11.322258118599724, 6.910963131905756, 6.906977941612571, 18.167211407818055, 30.17941537930656, 24.918058009903774, 32.623931200863765, 16.267831354180654, 85.0440953161135, 85.23076408361696, 92.04061867537708, 102.21030740338094, 31.419941862258256, 72.29354736159613, 160.58456695669364, 84.12221117794026, 39.271013042527656, 47.153525908302136, 110.9903156769949, 32.52656888050932, 35.56961213374261, 88.51387155669481, 93.20958887097927, 63.84974612826229, 50.271962739499656, 49.696057546593096, 72.6346942154107, 46.82621040883037, 53.9849678768907, 144.62866634727268, 123.50896845655298, 113.19861054790803, 73.61038906890633, 79.16133829903102, 74.66204969189869, 169.46520342296105, 100.42960965644951, 76.12853270707191, 92.20105914345217, 67.16061893470109, 66.50125650021168, 62.63129522802725, 86.66947068148008, 95.41631280398157, 65.25389352558287, 67.84173831149364, 65.61364145319355, 73.42554374783133, 48.67768498296601, 46.70642783836331, 43.73337493489194, 39.77817876808451, 37.80010747839437, 34.82722841019428, 39.61877024477509, 32.84180904847272, 29.88139792837259, 26.912817657013, 26.89959101139301, 27.86029549757165, 25.925615833025656, 24.93520264611288, 24.92786072259937, 23.94619677327186, 23.93872466553856, 22.949710429481584, 22.94066110961127, 49.61478194372418, 21.955319680146996, 20.97470862289919, 20.95696065584778, 78.92743956978492, 19.982341472209395, 19.972841684788598, 19.967439518925566, 18.99653596416779, 18.994551077568108, 63.224259726459294, 40.66068656369511, 70.96278176057129, 59.00465760184129, 38.64663320997931, 57.99120476200667, 43.21771150153894, 36.74625566194082, 71.47530467432676, 44.379150265041275, 58.02965358273087, 32.82823725515498, 96.08418538831448, 58.465154170308594, 40.50565929609296, 142.9836847835169, 83.85420121427475, 111.14875577393464, 172.6235320002638, 287.8781423603004, 84.13213702614405, 92.01772270153522, 205.40634873734732, 470.8902208582248, 140.7626514325598, 113.01139950261603, 71.05038233620013, 67.16518889885641, 73.87620209973896, 83.76171945290716, 50.00246714063654, 148.6461501680541, 138.13586962558068, 96.83009236355015, 140.0240462072744, 76.83350051553279, 129.5803754748472, 125.62152536157629, 118.3621020472275, 110.56501449328091, 148.84517946191198, 119.60071243642385, 108.76991140081117, 105.30536803757713, 99.52164947706412, 90.46561781119007, 91.57849254494347, 96.15786407278655, 83.84436994950622, 27.814826569302788, 48.93684709004376, 18.503509985385993, 14.879468477087567, 15.473941152164263, 9.373352607053878, 8.429864173735865, 7.54627241966446, 18.41492046315916, 7.518959799427076, 84.441554361045, 18.268486568333234, 6.622128289059269, 19.541713824662732, 18.58713025433588, 23.14611199920266, 38.251971813159585, 4.773288678682481, 17.381566736920462, 10.238816773832239, 14.802706325018894, 7.011676741661534, 4.6632729137915625, 25.4795958824361, 10.014582060857446, 7.5823981589187515, 4.540015041328993, 12.853649254073662, 19.425628383036667, 29.706978723475057, 46.82501087835097, 21.45040054139247, 52.99436840195971, 54.95528137360965, 16.311008295186422, 25.620730698223632, 83.62014229714084, 24.941675902345892, 28.633459492336474, 67.0124173425636, 33.33126174190001, 43.627376544116856, 49.3203792083094, 46.41828570415986, 34.85619603196497, 67.66899625922105, 32.10381351159178, 51.62302814445653, 31.177936996002924, 33.89549304217487, 35.04082063901764, 44.493279558925806, 35.22883442674165, 56.48861252778325, 47.16711951156645, 55.68778966133654, 39.641505360522075, 42.71566054538849, 38.01482404768326, 43.01510978367251, 42.90256178570261, 38.257154409179265, 34.06878160168586, 37.62879650451414, 34.84607073269746, 24.895381739117894, 17.608710471055893, 22.617152720693426, 12.988354717680876, 12.08165117895215, 17.255761258059323, 11.043916669732523, 28.50439130794209, 36.7518717272335, 17.292619041590687, 17.28997371525972, 6.5862018223720185, 15.53127637153608, 5.669749860722179, 16.06995842193471, 20.125736782358153, 5.6266276152891015, 6.416436823858539, 14.34317148979422, 4.761534756745229, 5.547238482984885, 5.532508833757199, 35.5695081440241, 10.223530392476105, 22.866566967658443, 19.4993734117372, 10.91357282723516, 5.430408333634509, 101.16733937850309, 9.141628146127154, 29.604377811542932, 21.94557072459186, 28.494458626329152, 31.902747941397156, 82.24350507900932, 23.619992267391083, 32.823688144756005, 43.57399739685004, 25.757310222259687, 22.21335819721855, 63.52515544416791, 175.30239292056663, 50.03986268624479, 41.16101243435981, 86.65875331991771, 128.39237926387378, 39.9103417174386, 33.81578682770494, 65.01077528351217, 47.42060534620182, 40.209279592813274, 156.29426259716976, 38.83917469224584, 66.04762002987088, 93.49618556474617, 54.83909075025158, 32.983787896321324, 41.66456800174167, 29.98997040790949, 43.233051375568415, 57.37752089386201, 52.70114914664655, 42.224181185310336, 42.5271536013297, 36.82910800278617, 37.096810629375895, 36.74442128741966, 37.17615767602712], \"Total\": [328.0, 485.0, 803.0, 307.0, 298.0, 123.0, 199.0, 172.0, 93.0, 107.0, 120.0, 273.0, 167.0, 178.0, 282.0, 122.0, 153.0, 124.0, 117.0, 297.0, 86.0, 147.0, 105.0, 237.0, 97.0, 97.0, 127.0, 230.0, 142.0, 95.0, 36.026039124999826, 36.02588883819035, 33.10322172299763, 33.10319945151618, 35.05056255948609, 32.128537874832695, 27.257595896582217, 26.283381057698197, 24.334723323645914, 26.28457560730935, 22.38617131270355, 32.134917729304696, 20.43764235373041, 53.48541765786132, 21.413009212119366, 18.488977697815788, 24.319878358135625, 17.514841028502037, 18.489977886518634, 16.540707205667303, 16.540683839194838, 16.54015211825248, 15.566432075823165, 15.56636855315957, 15.566439385894084, 15.566408536159056, 16.541123102771508, 15.566128130021546, 35.96189057796922, 29.21687336390235, 60.42030248595254, 97.50813665440417, 85.71452146351676, 82.76557482881309, 58.48806964583601, 32.15043643449321, 124.77305109139071, 55.495934070275894, 37.89639184076527, 53.448753785668835, 29.186855354435647, 98.42108266493295, 34.10865925517124, 307.99715835781416, 167.83422712513695, 178.18542278378112, 139.8217103611608, 103.42674442190588, 54.56223811623197, 68.76954856434928, 84.83647160041036, 64.2620139704154, 237.7527797142563, 90.51973633420364, 137.7059309562873, 91.77444009129962, 147.79376856176168, 70.06214294099412, 129.8665751690667, 73.99592681862175, 191.48072080434144, 803.8548070648299, 274.8542726057724, 186.07372334983492, 163.1589979967047, 306.4340359076893, 190.1554441273064, 123.89985251249688, 254.8494682894126, 162.7169852126023, 213.57338284403212, 283.0153604519204, 121.95636925526733, 161.53017716157902, 163.2099130129019, 234.12184367687414, 302.3464743334503, 268.51376419796026, 38.38900181276883, 42.21975114655715, 26.870239511488474, 39.32530511253746, 23.031355908186345, 22.069023878838742, 56.676640666140926, 52.83541185825132, 86.46800449904785, 18.221477632163268, 14.390064081926612, 17.262361508112317, 11.511442662430957, 18.23745719845575, 16.292903446551136, 78.46760127905365, 16.284197226960202, 26.80226895725758, 31.64526338081064, 19.14727441136656, 40.189557722273285, 8.631750433563736, 12.458169098970636, 7.671836647717204, 7.671950307157877, 20.188446423100274, 33.58228715547514, 27.75816573167878, 36.446484492775724, 18.179838892874383, 95.59958109020079, 96.93212392160395, 105.65758026062845, 117.78573708942221, 35.55944348942249, 85.01192732215911, 199.00113683933085, 101.02292341395624, 45.143814883594345, 54.90118963074975, 142.66262791524005, 37.27576952579075, 41.99097586369721, 120.33277045687882, 129.77818451581413, 84.8325637860814, 63.727084038072, 62.8441872366801, 102.98876739202458, 59.70895018137996, 72.90815716855995, 282.9442741244362, 230.32157269786694, 209.32374748162172, 115.94033775080966, 128.99304695412937, 119.71572579817425, 485.5254739281197, 211.37539248235055, 138.5374085496047, 215.73422314818592, 114.91801537520543, 112.93575546782287, 99.90679935398613, 203.57909034218503, 253.44869724604655, 123.30539886857127, 172.80964183116538, 200.80538207395298, 74.18132611605135, 49.44169052826699, 47.46260119923949, 44.49359036010502, 40.53551399617142, 38.55638985076481, 35.587527828435526, 40.5240890113041, 33.60786999510348, 30.639652232810256, 27.670894341231357, 27.670809878218474, 28.65913593377035, 26.681481371686992, 25.691806203590666, 25.691678325478726, 24.702282074756592, 24.702154272987823, 23.712487033002063, 23.71193932275299, 51.344361291669166, 22.72241627183326, 21.73341108202851, 21.732251919217553, 81.93116365784145, 20.743599793201994, 20.74291137765741, 20.743329613458673, 19.754257834892886, 19.754312772549607, 66.10674015267472, 42.43698376216307, 74.99667222533039, 62.13038324129472, 40.45277924173409, 61.207324272859495, 45.37927277280933, 38.47958552212633, 78.03996648950981, 47.29725623534736, 63.027230870364676, 34.52865293710656, 108.3411986273916, 64.00922906655566, 43.34070314169644, 171.40817645781544, 96.50766365165038, 132.0418807915385, 217.90548917781666, 392.8566393536838, 99.38191347480675, 110.41190710132193, 297.0893859119432, 803.8548070648299, 190.95279899715126, 148.1289582730565, 84.33186741272122, 80.65436811910901, 91.54281280787278, 111.05863796939248, 55.265203097107154, 262.87614880789033, 256.0899824588553, 148.46972078147343, 268.51376419796026, 105.84498183835278, 283.0153604519204, 298.72403397416906, 265.61772341053467, 234.12184367687414, 485.5254739281197, 302.3464743334503, 254.8494682894126, 282.9442741244362, 273.10491963972123, 193.49518722056052, 215.73422314818592, 328.08766300343245, 171.6826664515605, 28.587671191002897, 50.7523510400547, 19.380805810594, 15.693304333758899, 16.63341486307522, 10.165631588135193, 9.245712123820633, 8.32222688895906, 20.348539793129646, 8.322341294361463, 93.52912134200905, 20.35067352827829, 7.401195317063841, 22.202972880525138, 21.26355699827259, 26.864176614307784, 44.46685073473467, 5.559156794388778, 20.429848324794328, 12.080566726948911, 17.616166085442217, 8.344571664079329, 5.563614525856898, 30.740062340111134, 12.09712198877598, 9.309062259927517, 5.575810965371219, 15.79010291024103, 24.23635962717948, 37.140658075135576, 59.642613248128505, 27.081082977874384, 68.97438698866307, 71.68275492289163, 20.46714171356445, 33.34760135025249, 120.99975166695648, 32.58028930812076, 39.89608051957487, 122.310787768478, 52.4985276015062, 75.23212830270079, 89.45812584148688, 84.56146294600377, 57.49325835273576, 198.00621277778868, 57.79720640203344, 140.21994582812482, 57.24356765830154, 68.34216300022536, 74.7287103777943, 131.4090715711945, 82.98496450235835, 256.9778623927557, 171.6826664515605, 297.0893859119432, 117.36282478725464, 173.02514764709468, 153.0306200256714, 262.87614880789033, 306.4340359076893, 193.49518722056052, 99.64739691842243, 256.0899824588553, 217.96093203160194, 25.719900356958078, 18.37920616005875, 23.884995096222152, 13.795801363596551, 12.877393873437669, 18.39587213444211, 11.965555537317092, 31.301788527830023, 40.525553449448104, 19.305747619464736, 19.30538173564194, 7.373665018594333, 17.516110794478614, 6.456504867903854, 18.386543136831946, 23.075914689335093, 6.4593709563274, 7.374057915469383, 16.593451639249718, 5.538818995171563, 6.4622195262413475, 6.457204216744032, 41.58244844081568, 11.963052970316308, 26.870254060738766, 23.091351462145553, 12.931560935207836, 6.4716928154846745, 123.04949327572965, 11.129093826135714, 36.087265967704134, 26.774612595552767, 35.19197255344366, 39.79154818535321, 107.51555928474936, 29.57370429691552, 42.54665994150663, 57.80855935459387, 33.29164203718915, 28.65897514261255, 97.16968285832564, 328.08766300343245, 79.94285226747917, 64.56516799991901, 172.80964183116538, 298.72403397416906, 62.79076549191261, 50.55168073966484, 127.86759220361657, 82.87435176840464, 65.84647973719704, 485.5254739281197, 64.87874739797832, 153.0306200256714, 273.10491963972123, 119.84296064796638, 52.256274530524905, 81.4956681210071, 44.58064300425599, 112.6380460193117, 253.44869724604655, 203.57909034218503, 114.38793137157589, 173.02514764709468, 93.38657624530403, 103.89058589990485, 128.42114372832089, 302.3464743334503], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.6963, -6.6965, -6.7828, -6.7829, -6.726, -6.8147, -6.9821, -7.0195, -7.0991, -7.0234, -7.1856, -6.8254, -7.2798, -6.3188, -7.2344, -7.3841, -7.1105, -7.4407, -7.3869, -7.5003, -7.5004, -7.5014, -7.5641, -7.5641, -7.5641, -7.5642, -7.5042, -7.565, -6.7285, -6.9362, -6.2126, -5.7587, -5.8906, -5.9323, -6.2719, -6.8586, -5.5703, -6.3422, -6.7057, -6.3818, -6.9581, -5.8285, -6.8147, -4.8025, -5.3559, -5.3018, -5.5275, -5.82, -6.3911, -6.1939, -6.0132, -6.262, -5.1844, -5.9919, -5.6492, -5.9992, -5.6387, -6.2238, -5.7689, -6.1997, -5.5336, -4.5548, -5.2958, -5.5709, -5.6749, -5.2707, -5.5804, -5.8544, -5.4282, -5.7196, -5.5976, -5.4516, -5.9235, -5.8542, -5.8616, -5.7851, -5.8054, -5.8271, -6.5177, -6.4254, -6.883, -6.5073, -7.0434, -7.0902, -6.1517, -6.2254, -5.7345, -7.2989, -7.5353, -7.3547, -7.7713, -7.3118, -7.4284, -5.8681, -7.4414, -6.9436, -6.7812, -7.286, -6.5457, -8.0842, -7.7185, -8.2122, -8.2128, -7.2457, -6.7381, -6.9297, -6.6602, -7.3561, -5.7021, -5.6999, -5.6231, -5.5183, -6.6978, -5.8646, -5.0665, -5.713, -6.4748, -6.2919, -5.4358, -6.6632, -6.5738, -5.6621, -5.6104, -5.9888, -6.2278, -6.2394, -5.8598, -6.2988, -6.1566, -5.1711, -5.329, -5.4161, -5.8465, -5.7738, -5.8323, -5.0126, -5.5358, -5.8129, -5.6213, -5.9382, -5.9481, -6.008, -5.6832, -5.587, -5.967, -5.9281, -5.9615, -6.2979, -6.7089, -6.7502, -6.816, -6.9108, -6.9618, -7.0437, -6.9148, -7.1024, -7.1969, -7.3015, -7.302, -7.2669, -7.3389, -7.3778, -7.3781, -7.4183, -7.4186, -7.4608, -7.4612, -6.6898, -7.5051, -7.5508, -7.5517, -6.2256, -7.5993, -7.5997, -7.6, -7.6499, -7.65, -6.4474, -6.8889, -6.332, -6.5165, -6.9397, -6.5338, -6.8279, -6.9901, -6.3248, -6.8014, -6.5332, -7.1028, -6.0289, -6.5257, -6.8927, -5.6314, -6.165, -5.8833, -5.443, -4.9316, -6.1617, -6.0721, -5.2691, -4.4395, -5.647, -5.8666, -6.3307, -6.387, -6.2917, -6.1661, -6.6821, -5.5926, -5.6659, -6.0212, -5.6523, -6.2525, -5.7298, -5.7608, -5.8204, -5.8885, -5.5912, -5.81, -5.9049, -5.9373, -5.9937, -6.0892, -6.0769, -6.0281, -6.1652, -6.3178, -5.7528, -6.7254, -6.9434, -6.9042, -7.4055, -7.5116, -7.6223, -6.7302, -7.6259, -5.2073, -6.7382, -7.753, -6.6708, -6.7209, -6.5015, -5.9992, -8.0803, -6.788, -7.3172, -6.9486, -7.6958, -8.1037, -6.4055, -7.3393, -7.6175, -8.1304, -7.0897, -6.6768, -6.252, -5.797, -6.5776, -5.6732, -5.6369, -6.8515, -6.4, -5.2171, -6.4268, -6.2888, -5.4385, -6.1369, -5.8677, -5.745, -5.8057, -6.0921, -5.4287, -6.1744, -5.6994, -6.2037, -6.1201, -6.0869, -5.848, -6.0815, -5.6093, -5.7897, -5.6236, -5.9635, -5.8888, -6.0054, -5.8818, -5.8844, -5.999, -6.115, -6.0156, -6.0924, -6.4228, -6.7691, -6.5188, -7.0734, -7.1458, -6.7893, -7.2356, -6.2874, -6.0333, -6.7872, -6.7873, -7.7525, -6.8946, -7.9023, -6.8605, -6.6355, -7.91, -7.7786, -6.9742, -8.0769, -7.9242, -7.9268, -6.066, -7.3128, -6.5078, -6.6671, -7.2475, -7.9454, -5.0207, -7.4246, -6.2495, -6.5489, -6.2878, -6.1748, -5.2278, -6.4754, -6.1463, -5.863, -6.3887, -6.5368, -5.486, -4.471, -5.7246, -5.92, -5.1755, -4.7824, -5.9508, -6.1165, -5.4629, -5.7784, -5.9434, -4.5857, -5.978, -5.4471, -5.0995, -5.6331, -6.1414, -5.9078, -6.2366, -5.8709, -5.5878, -5.6728, -5.8945, -5.8873, -6.0312, -6.0239, -6.0335, -6.0218], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4528, 1.4527, 1.4509, 1.4508, 1.4506, 1.4489, 1.4459, 1.4449, 1.4424, 1.441, 1.4393, 1.438, 1.4362, 1.4352, 1.435, 1.432, 1.4315, 1.4296, 1.4293, 1.4272, 1.4271, 1.4262, 1.4242, 1.4241, 1.4241, 1.4241, 1.4233, 1.4232, 1.4224, 1.4224, 1.4195, 1.3947, 1.3918, 1.3851, 1.3926, 1.4044, 1.3365, 1.3749, 1.3928, 1.3728, 1.4015, 1.3156, 1.3891, 1.2008, 1.2545, 1.2488, 1.2655, 1.2745, 1.3429, 1.3087, 1.2794, 1.3084, 1.0777, 1.2359, 1.159, 1.2148, 1.0989, 1.2602, 1.098, 1.2296, 0.945, 0.4892, 0.8213, 0.9363, 0.9637, 0.7377, 0.9051, 1.0594, 0.7645, 0.9218, 0.7718, 0.6362, 1.0062, 0.7944, 0.7768, 0.4924, 0.2164, 0.3134, 1.5678, 1.5651, 1.5593, 1.5542, 1.5532, 1.549, 1.5443, 1.5408, 1.5391, 1.5319, 1.5316, 1.5301, 1.5188, 1.5181, 1.5142, 1.5026, 1.5018, 1.5013, 1.4976, 1.4952, 1.4941, 1.4937, 1.4925, 1.4836, 1.483, 1.4826, 1.4812, 1.4801, 1.4773, 1.4769, 1.4711, 1.4594, 1.4501, 1.4462, 1.4643, 1.426, 1.3736, 1.405, 1.4487, 1.4359, 1.337, 1.4518, 1.4221, 1.281, 1.2571, 1.3039, 1.3509, 1.3533, 1.2389, 1.345, 1.2876, 0.917, 0.9649, 0.9733, 1.1338, 1.0998, 1.1159, 0.5355, 0.8439, 0.9894, 0.738, 1.0509, 1.0585, 1.1211, 0.7341, 0.6112, 0.9517, 0.6531, 0.4695, 1.129, 1.1237, 1.1232, 1.122, 1.1204, 1.1194, 1.1176, 1.1166, 1.1162, 1.1142, 1.1115, 1.111, 1.111, 1.1105, 1.1093, 1.1091, 1.1082, 1.1078, 1.1065, 1.1062, 1.105, 1.1049, 1.1037, 1.1029, 1.1019, 1.1018, 1.1014, 1.1011, 1.1001, 1.1, 1.0947, 1.0965, 1.084, 1.0876, 1.0936, 1.0853, 1.0904, 1.0931, 1.0514, 1.0756, 1.0566, 1.0887, 1.0192, 1.0486, 1.0716, 0.9579, 0.9987, 0.967, 0.9063, 0.8283, 0.9727, 0.957, 0.7702, 0.6044, 0.8343, 0.8686, 0.9679, 0.9562, 0.9248, 0.8572, 1.0392, 0.5691, 0.5219, 0.7118, 0.4882, 0.8189, 0.358, 0.273, 0.3309, 0.389, -0.0431, 0.2118, 0.2878, 0.1509, 0.1298, 0.379, 0.2824, -0.0881, 0.4226, 2.0626, 2.0536, 2.0437, 2.0367, 2.0177, 2.0088, 1.9976, 1.9921, 1.9901, 1.9885, 1.9878, 1.9821, 1.9788, 1.9623, 1.9555, 1.941, 1.9394, 1.9376, 1.9284, 1.9246, 1.916, 1.916, 1.9135, 1.9023, 1.9011, 1.8848, 1.8845, 1.8842, 1.8687, 1.8667, 1.848, 1.8569, 1.8264, 1.8243, 1.863, 1.8264, 1.7205, 1.8228, 1.7583, 1.4883, 1.6357, 1.5451, 1.4946, 1.4902, 1.5896, 1.0163, 1.502, 1.0907, 1.4824, 1.3887, 1.3326, 1.007, 1.2332, 0.575, 0.798, 0.4157, 1.0046, 0.6911, 0.6973, 0.2799, 0.1239, 0.4691, 1.0167, 0.1722, 0.2566, 2.0633, 2.0531, 2.0414, 2.0356, 2.0321, 2.0319, 2.0157, 2.0023, 1.9982, 1.9858, 1.9856, 1.983, 1.9756, 1.966, 1.9612, 1.9591, 1.9579, 1.9568, 1.9502, 1.9447, 1.9432, 1.9413, 1.9397, 1.9388, 1.9346, 1.9268, 1.9262, 1.9205, 1.9001, 1.8992, 1.8979, 1.897, 1.8848, 1.8749, 1.8279, 1.8711, 1.8364, 1.8132, 1.8393, 1.8411, 1.6709, 1.4691, 1.6274, 1.6457, 1.4057, 1.2515, 1.6427, 1.6938, 1.4195, 1.5376, 1.6027, 0.9624, 1.5828, 1.2556, 1.024, 1.3141, 1.6358, 1.425, 1.6995, 1.1383, 0.6104, 0.7445, 1.0993, 0.6926, 1.1654, 1.0661, 0.8446, -0.0]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 2, 3, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 1, 2, 3, 4, 5, 2, 5, 2, 3, 4, 5, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 5, 2, 4, 5, 1, 2, 4, 5, 1, 3, 4, 5, 1, 2, 2, 5, 3, 1, 5, 3, 4, 2, 3, 1, 3, 4, 1, 2, 3, 4, 5, 2, 5, 3, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 4, 3, 2, 3, 5, 3, 3, 4, 1, 3, 4, 3, 4, 3, 2, 4, 3, 4, 3, 1, 2, 3, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 5, 2, 3, 4, 2, 4, 5, 2, 3, 5, 2, 3, 4, 5, 2, 5, 2, 3, 5, 2, 5, 1, 2, 3, 4, 5, 1, 5, 2, 3, 4, 5, 2, 3, 4, 5, 5, 2, 3, 4, 3, 5, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 4, 3, 2, 5, 2, 3, 4, 5, 1, 2, 4, 2, 4, 1, 2, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 3, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 5, 2, 1, 2, 4, 1, 1, 2, 4, 1, 4, 5, 1, 3, 4, 1, 4, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 5, 1, 2, 5, 1, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 2, 3, 4, 5, 1, 3, 1, 3, 1, 1, 1, 5, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 2, 3, 4, 5, 2, 4, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 2, 3, 4, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 1, 3, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 2, 3, 5, 1, 2, 4, 1, 2, 3, 4, 5, 2, 4, 2, 3, 2, 4, 3, 4, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 2, 1, 3, 4, 5, 3, 1, 3, 2, 4, 1, 2, 3, 4, 5, 1, 3, 1, 4, 2, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 1, 3, 4, 1, 2, 3, 4, 5, 2, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 1, 2, 3, 4, 5, 1, 2, 4, 5, 3, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 3, 3, 1, 2, 3, 4, 5, 3, 4, 2, 3, 4, 5, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 4, 2, 3, 4, 5, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 2, 3, 4, 5, 4, 5, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 3, 1, 4, 4, 5, 3, 4, 1, 2, 5, 5, 3, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 3, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 3, 4, 3, 4, 5, 1, 3, 1, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 5, 1, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 2, 4, 5, 3, 4, 5, 2, 4, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 5, 3, 5, 1, 3, 3, 2, 3, 4, 5, 4, 2, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 5, 2, 3, 5, 5, 1, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 2, 3, 5, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 1, 3, 4, 2, 5, 1, 2, 3, 4, 5], \"Freq\": [0.0035342648409990777, 0.5124684019448662, 0.37109780830490313, 0.021205589045994466, 0.09542515070697509, 0.7845957610445328, 0.20399489787157854, 0.7166073431137224, 0.19263638255745227, 0.09246546362757709, 0.008701855812032748, 0.5830243394061941, 0.21754639530081868, 0.05221113487219649, 0.1479315488045567, 0.017484361995351, 0.17484361995351003, 0.39339814489539754, 0.04371090498837751, 0.367171601902371, 0.9291947100637662, 0.9794431946877908, 0.015641179798046065, 0.2189765171726449, 0.08602648888925336, 0.17987356767752974, 0.5083383434364971, 0.07733018504188242, 0.8506320354607066, 0.28156351428108395, 0.3120028131222822, 0.33483228725318087, 0.06848842239269609, 0.9292953575899554, 0.154133678609085, 0.2312005179136275, 0.6011213465754315, 0.010035385077029783, 0.37130924785010194, 0.20070770154059564, 0.3412030926190126, 0.07024769553920848, 0.9527734771383518, 0.0352879065606797, 0.9730777290328759, 0.08359070234674047, 0.8359070234674048, 0.0380407277166404, 0.1521629108665616, 0.5668068429779419, 0.16357512918155373, 0.08368960097660888, 0.9700272268753711, 0.3979431088764665, 0.5536599775672577, 0.03460374859795361, 0.8967305439608132, 0.0600559725543906, 0.6305877118211013, 0.1801679176631718, 0.0600559725543906, 0.0600559725543906, 0.20872012378176497, 0.05218003094544124, 0.1391467491878433, 0.6087670276968145, 0.9329649517552188, 0.08985457536997186, 0.8086911783297468, 0.13525529165506645, 0.03381382291376661, 0.8115317499303986, 0.10859057916849099, 0.626484110587448, 0.10859057916849099, 0.15870930801548683, 0.6618248394745204, 0.2905572465985699, 0.02421310388321416, 0.032284138510952215, 0.9715235662110071, 0.9555709325556462, 0.8800958080146258, 0.055005988000914115, 0.9870672228767955, 0.9454452881525894, 0.0278072143574291, 0.9530041846640804, 0.030254101100447, 0.8560834531293225, 0.12750179089160124, 0.840309798333744, 0.108929047932152, 0.031122585123472, 0.13292865408738866, 0.034677040196710085, 0.3409908952676492, 0.24851878807642228, 0.24851878807642228, 0.9662989235876283, 0.025428919041779692, 0.9618179614138374, 0.06389411257512731, 0.926464632339346, 0.9735003530276861, 0.10987764301333924, 0.5398336374133623, 0.12898679832000692, 0.14809595362667463, 0.07165933240000386, 0.04333522694388215, 0.04333522694388215, 0.866704538877643, 0.6006410998060879, 0.09193486221521753, 0.30032054990304397, 0.006128990814347836, 0.9558216473080505, 0.9715751806410002, 0.12149472579140408, 0.2733631330306592, 0.6074736289570204, 0.9791233846928168, 0.16265419193622635, 0.8132709596811318, 0.09789597887384877, 0.04894798943692438, 0.8321158204277145, 0.18463072559118365, 0.7754490474829713, 0.9770008441533765, 0.1116728810665356, 0.8561587548434395, 0.9557279880019943, 0.028961454181878614, 0.9699530870797967, 0.06424803731573567, 0.08719376492849841, 0.7939221754015908, 0.055069746270630576, 0.09401443040415441, 0.04700721520207721, 0.07051082280311581, 0.775619050834274, 0.10467924917312728, 0.03489308305770909, 0.06978616611541819, 0.7676478272696, 0.15436913612108982, 0.12349530889687187, 0.07203893018984192, 0.6586416474499832, 0.8853360385895098, 0.9182561730187151, 0.0483292722641429, 0.02416463613207145, 0.8986963379224964, 0.9636119521118193, 0.9666732823702414, 0.05024372377820738, 0.7871516725252489, 0.13398326340855302, 0.033495815852138254, 0.9699754915419405, 0.041867289315800124, 0.9629476542634028, 0.9673429775983494, 0.16532857995940284, 0.8266428997970142, 0.18181855497152996, 0.024793439314299538, 0.09917375725719815, 0.6942163008003871, 0.09771760160699501, 0.09771760160699501, 0.048858800803497505, 0.7817408128559601, 0.9672861933612693, 0.9250739647050295, 0.034261998692778864, 0.585789320693446, 0.05374213951316018, 0.295581767322381, 0.04836792556184417, 0.016122641853948055, 0.05402551399607104, 0.7563571959449945, 0.18908929898624863, 0.06026473706257871, 0.06026473706257871, 0.843706318876102, 0.026667849927939778, 0.9467086724418621, 0.026667849927939778, 0.5485882895866891, 0.20211147511088545, 0.1515836063331641, 0.09383747058719683, 0.9327568512900264, 0.07462054810320211, 0.9515599835902215, 0.9889064839202639, 0.9284735647923446, 0.9268108550604944, 0.949324383783091, 0.07762613232457267, 0.6382593102242643, 0.02587537744152423, 0.04312562906920704, 0.21562814534603522, 0.9535309292383172, 0.018696684887025826, 0.15686397205650512, 0.2654621065571625, 0.012066459388961932, 0.5671235912812108, 0.2456422548185363, 0.7274789854241267, 0.009447779031482166, 0.01889555806296433, 0.9720099865486718, 0.12666161907677337, 0.06333080953838668, 0.8233005239990269, 0.9615488186255139, 0.025987805908797672, 0.9662542120396842, 0.11983838598986156, 0.838868701929031, 0.03809630653227348, 0.057144459798410215, 0.1904815326613674, 0.6285890577825124, 0.07619261306454696, 0.284441881419635, 0.09922391212312849, 0.39689564849251396, 0.09591644838569088, 0.12237615828519181, 0.9318655713989243, 0.9496159032346975, 0.048285554401764276, 0.971570154019322, 0.05436002124235937, 0.9241203611201093, 0.26138559716538995, 0.05881175936221274, 0.24831631730712045, 0.4312862353228934, 0.3345434421872316, 0.18734432762484968, 0.46836081906212423, 0.11353208128826484, 0.8514906096619863, 0.010050193841931445, 0.8090406042754814, 0.055276066130622956, 0.12562742302414306, 0.8735860752508355, 0.10418916493817305, 0.01602910229818047, 0.7969226538374563, 0.01683639409515753, 0.14030328412631274, 0.01683639409515753, 0.028060656825262546, 0.8135634681914458, 0.12845738971443882, 0.05709217320641725, 0.9088601157871682, 0.05863613650239795, 0.9862450326969338, 0.031085614203952363, 0.07253309980922218, 0.8703971977106661, 0.02072374280263491, 0.011825717828918643, 0.34294581703864063, 0.0827800248024305, 0.5439830201302576, 0.023651435657837287, 0.9640870350822448, 0.024720180386724227, 0.9676132581134456, 0.061386809094463514, 0.15346702273615878, 0.767335113680794, 0.9827495596585376, 0.10410989890991255, 0.8707373363374504, 0.01892907252907501, 0.07469762607628533, 0.07469762607628533, 0.8216738868391387, 0.8534756753893022, 0.12192509648418604, 0.020320849414031006, 0.019703520713962225, 0.965472514984149, 0.32848581192234444, 0.221949872920503, 0.07102395933456096, 0.38175378142326516, 0.06415114259503978, 0.010691857099173295, 0.02138371419834659, 0.8981159963305568, 0.9648742846864278, 0.05709029885305462, 0.9134447816488739, 0.9735530159748338, 0.2325244845147371, 0.7626803092083376, 0.9457284144805728, 0.9211384381396414, 0.06140922920930943, 0.9807122292794975, 0.9457931726056649, 0.07646695338815275, 0.10923850484021821, 0.8083649358176147, 0.010923850484021821, 0.9682068903592455, 0.020201386329675306, 0.22221524962642836, 0.2676683688681978, 0.3434235676044802, 0.15151039747256478, 0.4797117251175145, 0.08158362672066573, 0.21864411961138414, 0.14032383795954503, 0.08158362672066573, 0.6901508838471435, 0.3112445162447902, 0.20504940033257163, 0.36615964345102076, 0.08787831442824498, 0.3405284684094493, 0.9331133050440935, 0.06220755366960624, 0.964682724914222, 0.03111879757787813, 0.9715195133875314, 0.9785864560033007, 0.9673118811500627, 0.928883019812105, 0.2769443032388644, 0.05934520783689951, 0.6725790221515279, 0.9673105146627563, 0.21104699622650955, 0.2936306034455785, 0.2569267780148812, 0.16057923625930073, 0.07799562904023179, 0.31283312515060296, 0.08938089290017229, 0.5213885419176716, 0.044690446450086144, 0.033517834837564604, 0.3758726593724171, 0.06834048352225766, 0.4741121044356625, 0.06834048352225766, 0.017085120880564415, 0.8433965499384956, 0.043623959479577354, 0.014541319826525786, 0.08724791895915471, 0.012508935716405517, 0.2626876500445159, 0.08756255001483862, 0.6254467858202759, 0.055421211509618824, 0.08313181726442824, 0.027710605754809412, 0.8313181726442823, 0.9175761566094907, 0.07646467971745755, 0.8769022751296122, 0.06189898412679615, 0.030949492063398074, 0.02063299470893205, 0.12015027662293477, 0.030037569155733693, 0.06007513831146739, 0.780976798049076, 0.08524671344989553, 0.08524671344989553, 0.028415571149965176, 0.7956359921990249, 0.12532559426600234, 0.025065118853200466, 0.7268884467428135, 0.12532559426600234, 0.9124281865520282, 0.9006358792457585, 0.07205087033966068, 0.07479259362041485, 0.7396156480241025, 0.13296461088073752, 0.01662057636009219, 0.03324115272018438, 0.12251457564025962, 0.01166805482288187, 0.8342659198360537, 0.02333610964576374, 0.005834027411440935, 0.015925908725046505, 0.2707404483257906, 0.07962954362523253, 0.6370363490018602, 0.9641528085474497, 0.007573354711440024, 0.8406423729698427, 0.053013482980080164, 0.0984536112487203, 0.9840751550571737, 0.784359332840567, 0.15466240365870335, 0.01104731454705024, 0.04418925818820096, 0.590137740892805, 0.010444915768014248, 0.28723518362039185, 0.06266949460808549, 0.04700212095606412, 0.1463225563985592, 0.33654187971668614, 0.49749669175510125, 0.01463225563985592, 0.9268720268939403, 0.9738167686217319, 0.01947633537243464, 0.03618913688755972, 0.054283705331339575, 0.904728422188993, 0.016337913997711204, 0.9475990118672499, 0.016337913997711204, 0.4962933838068823, 0.4411496744950065, 0.04901663049944517, 0.018381236437291937, 0.6231736846882029, 0.008199653745897406, 0.20499134364743515, 0.10659549869666628, 0.05739757622128184, 0.0843526299249193, 0.40971277392103667, 0.03615112711067971, 0.42176314962459655, 0.04820150281423961, 0.5076450818101635, 0.04333555576428226, 0.2662041282663053, 0.14857904833468202, 0.037144762083670506, 0.9636134092945492, 0.6729679467566956, 0.008412099334458694, 0.20189038402700868, 0.05047259600675217, 0.06729679467566956, 0.8043651304768973, 0.17874780677264385, 0.005958260225754795, 0.01191652045150959, 0.015573759444403215, 0.4672127833320964, 0.18688511333283858, 0.03893439861100804, 0.28811454972145945, 0.685318757995546, 0.12320337222391838, 0.10780295069592859, 0.04620126458396939, 0.03850105381997449, 0.9216641317145461, 0.02333326915733028, 0.04666653831466056, 0.01166663457866514, 0.9463350098252615, 0.03785340039301046, 0.8933280768254315, 0.05955520512169543, 0.029777602560847716, 0.03160030580141702, 0.9164088682410936, 0.03160030580141702, 0.4310720089721977, 0.021200262736337593, 0.4593390259539812, 0.08126767382262744, 0.003533377122722932, 0.857327062768345, 0.1428878437947242, 0.8915990672468892, 0.04953328151371606, 0.9711094662229761, 0.961281169900985, 0.9475691736022055, 0.04407298481870723, 0.04503901371140837, 0.9007802742281675, 0.04503901371140837, 0.8314944485995291, 0.05939246061425208, 0.0989874343570868, 0.030186579178317973, 0.0804975444755146, 0.8452242169929033, 0.030186579178317973, 0.04992157113354101, 0.07131653019077287, 0.5134790173735646, 0.37084595699201894, 0.04126032190406046, 0.12378096571218138, 0.7839461161771487, 0.17054687754266515, 0.1550426159478774, 0.4651278478436322, 0.19638731353397804, 0.01033617439652516, 0.5271464234042353, 0.4298270836988381, 0.0324397799017991, 0.007752355833222588, 0.6124361108245845, 0.16279947249767435, 0.031009423332890352, 0.18605653999734212, 0.9206371529561368, 0.07464625564509217, 0.9552194880623699, 0.03124549426959096, 0.9061193338181378, 0.01562274713479548, 0.03124549426959096, 0.9855694515768112, 0.9229998960905685, 0.07178888080704422, 0.13493197518737665, 0.8545691761867188, 0.11454560135227108, 0.12981834819924057, 0.7330918486545349, 0.010181831231312985, 0.012727289039141231, 0.7597472692528925, 0.23701517374128697, 0.20119842754167955, 0.7880271745382449, 0.049143575419482124, 0.8845843575506783, 0.023176665839269944, 0.426450651442567, 0.426450651442567, 0.11124799602849574, 0.013905999503561967, 0.14878301423524393, 0.8307051628134453, 0.012398584519603661, 0.012398584519603661, 0.01913645794661197, 0.21050103741273166, 0.1339552056262838, 0.631503112238195, 0.49048562211653224, 0.007847769953864516, 0.42770346248561614, 0.05101050470011935, 0.02354330986159355, 0.9663057504606767, 0.9538625526127231, 0.14491190687719258, 0.8332434645438572, 0.018113988359649072, 0.07700408974214214, 0.3368928926218719, 0.125131645830981, 0.10588062339544545, 0.3561439150574074, 0.0740273665538516, 0.9130041874975031, 0.17591675416581595, 0.8041908761865872, 0.24094777704679965, 0.14682755163789354, 0.44424746393003683, 0.12423869753975607, 0.04141289917991869, 0.8980564858907935, 0.018709510122724864, 0.018709510122724864, 0.03741902024544973, 0.9892182418587583, 0.5679563921803654, 0.0841416877304245, 0.168283375460849, 0.07362397676412144, 0.10517710966303064, 0.02352611054706299, 0.8469399796942677, 0.05881527636765748, 0.05881527636765748, 0.9910664355618167, 0.9124146689882817, 0.9302865219297187, 0.0211428754984027, 0.0211428754984027, 0.05928956814782645, 0.8419118676991356, 0.04743165451826117, 0.04743165451826117, 0.1462141275033569, 0.026584386818792168, 0.5848565100134276, 0.2392594813691295, 0.9641653665390156, 0.9730728856465537, 0.013463961318313785, 0.06731980659156893, 0.6900280175635815, 0.18849545845639298, 0.03702589362536291, 0.08277757348661752, 0.8277757348661752, 0.272658740602119, 0.2385763980268541, 0.3408234257526487, 0.15337054158869193, 0.8136632596027124, 0.8878548264764068, 0.05222675449861216, 0.04715170474025313, 0.7544272758440501, 0.011787926185063283, 0.10609133566556954, 0.08251548329544298, 0.015912370641915672, 0.7956185320957836, 0.06364948256766269, 0.12729896513532538, 0.8652659625199466, 0.5383777062110534, 0.21708778476252155, 0.09117686960025906, 0.1519614493337651, 0.010460296882017432, 0.8891252349714818, 0.010460296882017432, 0.08368237505613946, 0.8994169772377761, 0.008854591673448497, 0.5932576421210494, 0.07969132506103647, 0.15938265012207295, 0.15938265012207295, 0.863905722202776, 0.08860571509772061, 0.044302857548860305, 0.3286764493976232, 0.41333553484852614, 0.14939838608982872, 0.1095588164658744, 0.05179902752991318, 0.880583468008524, 0.9459929587657165, 0.04614599798857154, 0.11248769967926633, 0.8717796725143141, 0.9819128675755994, 0.05486354552553294, 0.7406578645946947, 0.10972709105106589, 0.05486354552553294, 0.04114765914414971, 0.9902533534287855, 0.06011994579777576, 0.9017991869666364, 0.10877520505709404, 0.8702016404567523, 0.10742220559687032, 0.8593776447749626, 0.05487497704741405, 0.9054371212823319, 0.027437488523707025, 0.9793676529466854, 0.986789016756467, 0.9641848068416464, 0.03883918704235078, 0.7088151635229017, 0.05825878056352617, 0.15535674816940312, 0.04854898380293848, 0.15488227336468083, 0.13939404602821276, 0.06195290934587234, 0.6350173207951915, 0.9483276557041738, 0.03469491423307953, 0.051798045831271754, 0.8805667791316198, 0.4963165287193556, 0.018728925612051153, 0.2809338841807673, 0.10300909086628135, 0.09832685946326856, 0.9618152865536385, 0.8218377217140456, 0.16436754434280912, 0.009668679078988772, 0.37320172419620223, 0.01741608046248944, 0.5859267069880375, 0.0037320172419620223, 0.019904091957130787, 0.8659792137868291, 0.050939953752166416, 0.008489992292027735, 0.07640993062824962, 0.9235707754728879, 0.02638773644208251, 0.05277547288416502, 0.05483220545047665, 0.932147492658103, 0.174740995232995, 0.04077289888769883, 0.48927478665238594, 0.27376089253169217, 0.017474099523299497, 0.011178414376486328, 0.10060572938837696, 0.25710353065918556, 0.5477423044478301, 0.08942731501189062, 0.058409771939481735, 0.33377012536846706, 0.14185230328159848, 0.45893392238164216, 0.1349764994093537, 0.2699529988187074, 0.07362354513237475, 0.5153648159266232, 0.902719515542704, 0.009824191652680581, 0.4273523368916053, 0.21613221635897278, 0.08841772487412523, 0.2603410787960354, 0.4176189080704319, 0.1177899484301218, 0.06424906278006644, 0.39620255381040975, 0.01625362239825234, 0.048760867194757015, 0.07314130079213553, 0.04063405599563085, 0.8208079311117431, 0.8852935947349823, 0.026827078628332796, 0.10730831451333118, 0.9433915034313549, 0.04965218439112395, 0.9728935132112081, 0.34535713520245914, 0.4730919660307659, 0.10881115218707617, 0.05204011626338425, 0.014192758980922978, 0.7838269279627939, 0.16217108854402632, 0.04054277213600658, 0.01351425737866886, 0.9834906253879745, 0.9642240689991601, 0.02441073592402937, 0.9661384095953519, 0.02356435145354517, 0.02356435145354517, 0.07688368242452442, 0.909790242023539, 0.9636114995952525, 0.008238496669676668, 0.3480764842938392, 0.30688400094545587, 0.01441736917193417, 0.32130137011739, 0.12191863489722721, 0.2926047237533453, 0.048767453958890886, 0.533394027675369, 0.051895429214871086, 0.19028324045452732, 0.7611329618181093, 0.049138422795218524, 0.8844916103139334, 0.11160285355390587, 0.013950356694238233, 0.055801426776952934, 0.7672696181831029, 0.055801426776952934, 0.014498135375445444, 0.11598508300356355, 0.10148694762811811, 0.7684011748986085, 0.014498135375445444, 0.9636307676968375, 0.8797293083496196, 0.09163846961975204, 0.01832769392395041, 0.7736358830341796, 0.07627396029914447, 0.02179256008546985, 0.14165164055555401, 0.9636158843839906, 0.021028632682852204, 0.7780594092655315, 0.08411453073140882, 0.05607635382093921, 0.0630858980485566, 0.9898668422100143, 0.39349656234132957, 0.10416085473741077, 0.5034441312308187, 0.0899614928369439, 0.7796662712535138, 0.1499358213949065, 0.4367302916762643, 0.5415455616785677, 0.9612679553793528, 0.9193054150886848, 0.8081720621791847, 0.014303930304056366, 0.10012751212839456, 0.05006375606419728, 0.028607860608112733, 0.06729378039059684, 0.11215630065099473, 0.15701882091139263, 0.6729378039059685, 0.1299187708834627, 0.8228188822619306, 0.1116476231753768, 0.8559651110112221, 0.9583503221324905, 0.034226797219017516, 0.9757545118362263, 0.026924671016248538, 0.10769868406499415, 0.8077401304874561, 0.053849342032497076, 0.9803513943478117, 0.04702882025247413, 0.8935475847970085, 0.04702882025247413, 0.11046985259597003, 0.4217939826391583, 0.03682328419865668, 0.42848912522073224, 0.02452768112064406, 0.08175893706881353, 0.3433875356890168, 0.5477848783610506, 0.7725953846320721, 0.24857101529640122, 0.3748293087802876, 0.07891143342742896, 0.07102029008468606, 0.22489758526817255, 0.88295478353307, 0.08026861668482455, 0.8251168239257772, 0.02357476639787935, 0.1414485983872761, 0.011787383198939676, 0.09619443178516056, 0.04809721589258028, 0.865749886066445, 0.9423156841257182, 0.9666739327377718, 0.03375437225976537, 0.16202098684687377, 0.7628488130706973, 0.03375437225976537, 0.013501748903906147, 0.9232652116403788, 0.0683900156770651, 0.5776901524888858, 0.30113635608463196, 0.03072819960047265, 0.09218459880141794, 0.5202757033546539, 0.09459558242811889, 0.2364889560702972, 0.10551045732367106, 0.04729779121405944, 0.11521171784618987, 0.05236896265735903, 0.7384023734687624, 0.06284275518883084, 0.03142137759441542, 0.7261851345512745, 0.24690294574743332, 0.021785554036538233, 0.08307089190468449, 0.8860895136499679, 0.027690297301561497, 0.970605440970647, 0.900966905731936, 0.07207735245855489, 0.01801933811463872, 0.28407116208488586, 0.2257003753551148, 0.16732958862534372, 0.21791760379114533, 0.10506741611358793, 0.10933656885426443, 0.17962436311772015, 0.5388730893531604, 0.14838534344507315, 0.023429264754485236, 0.9744586381020753, 0.9757574902516131, 0.9511281587155576, 0.01586615794777363, 0.9202371609708706, 0.06346463179109452, 0.9206462217865278, 0.06137641478576852, 0.06735380081113371, 0.2087967825145145, 0.653331867867997, 0.060618420730020335, 0.01347076016222674], \"Term\": [\"000\", \"000\", \"000\", \"000\", \"000\", \"1959\", \"1959\", \"1960\", \"1960\", \"1960\", \"1961\", \"1961\", \"1961\", \"1961\", \"1961\", \"30\", \"30\", \"30\", \"30\", \"30\", \"62\", \"academic\", \"act\", \"act\", \"act\", \"act\", \"act\", \"adjustments\", \"adjustments\", \"administration\", \"administration\", \"administration\", \"administration\", \"adopting\", \"agreement\", \"agreement\", \"agreement\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aircraft\", \"aircraft\", \"alexander\", \"allocation\", \"allocation\", \"american\", \"american\", \"american\", \"american\", \"american\", \"anne\", \"anti\", \"anti\", \"anti\", \"appearances\", \"areas\", \"areas\", \"areas\", \"areas\", \"areas\", \"art\", \"art\", \"art\", \"art\", \"assessment\", \"assigned\", \"assigned\", \"authorized\", \"authorized\", \"authorized\", \"available\", \"available\", \"available\", \"available\", \"away\", \"away\", \"away\", \"away\", \"baby\", \"bankers\", \"banks\", \"banks\", \"baseball\", \"bed\", \"bed\", \"berlin\", \"berlin\", \"billion\", \"billion\", \"black\", \"black\", \"black\", \"board\", \"board\", \"board\", \"board\", \"board\", \"boats\", \"boats\", \"bombs\", \"bonds\", \"bonds\", \"bride\", \"business\", \"business\", \"business\", \"business\", \"business\", \"calendar\", \"calendar\", \"calendar\", \"came\", \"came\", \"came\", \"came\", \"campus\", \"captain\", \"cars\", \"cars\", \"cars\", \"castro\", \"catholic\", \"catholic\", \"cattle\", \"cattle\", \"cattle\", \"chamber\", \"chamber\", \"charter\", \"chemical\", \"chemical\", \"china\", \"china\", \"chinese\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"claim\", \"claims\", \"claims\", \"claims\", \"claims\", \"class\", \"class\", \"class\", \"class\", \"classical\", \"clay\", \"clay\", \"clay\", \"clerical\", \"cloth\", \"clothes\", \"co\", \"co\", \"co\", \"co\", \"coach\", \"coal\", \"coal\", \"coat\", \"collective\", \"collective\", \"college\", \"college\", \"college\", \"college\", \"colleges\", \"colleges\", \"colleges\", \"colleges\", \"colored\", \"colors\", \"colors\", \"come\", \"come\", \"come\", \"come\", \"come\", \"committee\", \"committee\", \"committee\", \"commodities\", \"commodities\", \"commodities\", \"communist\", \"communist\", \"communist\", \"company\", \"company\", \"company\", \"company\", \"compared\", \"compared\", \"components\", \"congo\", \"connections\", \"conservation\", \"coordination\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"couldn\", \"couldn\", \"countries\", \"countries\", \"countries\", \"countries\", \"county\", \"county\", \"county\", \"county\", \"cousin\", \"creative\", \"creative\", \"creative\", \"cuba\", \"cuba\", \"cuban\", \"curriculum\", \"curriculum\", \"daily\", \"daily\", \"daily\", \"daily\", \"daily\", \"day\", \"day\", \"day\", \"day\", \"day\", \"definition\", \"democratic\", \"democratic\", \"democrats\", \"denied\", \"denied\", \"department\", \"department\", \"department\", \"department\", \"design\", \"design\", \"design\", \"designer\", \"designer\", \"development\", \"development\", \"development\", \"development\", \"didn\", \"didn\", \"didn\", \"don\", \"don\", \"don\", \"don\", \"don\", \"door\", \"door\", \"door\", \"drill\", \"drill\", \"dry\", \"east\", \"east\", \"east\", \"east\", \"education\", \"education\", \"education\", \"education\", \"education\", \"eisenhower\", \"eisenhower\", \"electronic\", \"engineer\", \"engineer\", \"engineer\", \"entrance\", \"equipment\", \"equipment\", \"equipment\", \"exercise\", \"exercise\", \"exercise\", \"eyes\", \"eyes\", \"eyes\", \"faculty\", \"faculty\", \"federal\", \"federal\", \"federal\", \"federal\", \"feed\", \"feed\", \"feed\", \"feed\", \"fig\", \"filing\", \"filing\", \"fingers\", \"fiscal\", \"fiscal\", \"flowers\", \"forests\", \"forests\", \"frames\", \"fulfill\", \"game\", \"game\", \"game\", \"game\", \"gen\", \"general\", \"general\", \"general\", \"general\", \"general\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"government\", \"government\", \"government\", \"government\", \"guests\", \"guests\", \"hadn\", \"hadn\", \"hair\", \"ham\", \"handsome\", \"hated\", \"hearing\", \"hearing\", \"hearing\", \"hell\", \"high\", \"high\", \"high\", \"high\", \"high\", \"home\", \"home\", \"home\", \"home\", \"home\", \"house\", \"house\", \"house\", \"house\", \"house\", \"inch\", \"inch\", \"inch\", \"inch\", \"income\", \"income\", \"income\", \"income\", \"india\", \"india\", \"india\", \"india\", \"industrial\", \"industrial\", \"industry\", \"industry\", \"industry\", \"industry\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"interference\", \"interference\", \"interference\", \"interference\", \"interior\", \"interior\", \"interior\", \"interior\", \"inventories\", \"investment\", \"investment\", \"island\", \"island\", \"island\", \"island\", \"island\", \"john\", \"john\", \"john\", \"john\", \"john\", \"junior\", \"junior\", \"junior\", \"junior\", \"katanga\", \"kennedy\", \"kennedy\", \"kennedy\", \"kennedy\", \"khrushchev\", \"knew\", \"knew\", \"knew\", \"knew\", \"know\", \"know\", \"know\", \"know\", \"know\", \"labor\", \"labor\", \"labor\", \"labor\", \"laboratory\", \"laos\", \"laos\", \"leaders\", \"leaders\", \"leaders\", \"league\", \"league\", \"league\", \"left\", \"left\", \"left\", \"left\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"liked\", \"little\", \"little\", \"little\", \"little\", \"little\", \"ll\", \"ll\", \"ll\", \"ll\", \"local\", \"local\", \"local\", \"local\", \"local\", \"look\", \"look\", \"look\", \"look\", \"look\", \"looked\", \"looked\", \"looked\", \"looked\", \"machine\", \"machine\", \"machinery\", \"machinery\", \"machinery\", \"machines\", \"machines\", \"machines\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manufacturers\", \"manufacturers\", \"manufacturing\", \"manufacturing\", \"marketing\", \"mathematics\", \"mayor\", \"mayor\", \"meat\", \"meat\", \"meat\", \"medical\", \"medical\", \"medical\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"members\", \"members\", \"members\", \"members\", \"membership\", \"membership\", \"membership\", \"men\", \"men\", \"men\", \"men\", \"men\", \"military\", \"military\", \"military\", \"million\", \"million\", \"million\", \"million\", \"million\", \"missile\", \"missile\", \"missiles\", \"monday\", \"monday\", \"monday\", \"monday\", \"moscow\", \"mother\", \"mother\", \"motors\", \"motors\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mrs\", \"mrs\", \"music\", \"music\", \"musical\", \"musical\", \"national\", \"national\", \"national\", \"national\", \"national\", \"nations\", \"nations\", \"nations\", \"nations\", \"officer\", \"officer\", \"officer\", \"officer\", \"old\", \"old\", \"old\", \"old\", \"old\", \"opposition\", \"pale\", \"party\", \"party\", \"party\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"payment\", \"payment\", \"payments\", \"payments\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pieces\", \"pieces\", \"pieces\", \"pieces\", \"pink\", \"place\", \"place\", \"place\", \"place\", \"place\", \"planning\", \"planning\", \"planning\", \"planning\", \"player\", \"polaris\", \"police\", \"police\", \"police\", \"political\", \"political\", \"political\", \"political\", \"pool\", \"pool\", \"pool\", \"pool\", \"pope\", \"premier\", \"president\", \"president\", \"president\", \"president\", \"president\", \"prestige\", \"prestige\", \"problem\", \"problem\", \"problem\", \"problem\", \"proceedings\", \"procurement\", \"procurement\", \"production\", \"production\", \"production\", \"production\", \"production\", \"products\", \"products\", \"products\", \"products\", \"professors\", \"program\", \"program\", \"program\", \"program\", \"property\", \"property\", \"property\", \"property\", \"prosperity\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"providence\", \"providence\", \"providence\", \"public\", \"public\", \"public\", \"public\", \"puerto\", \"puerto\", \"race\", \"race\", \"radiation\", \"radiation\", \"railroad\", \"range\", \"range\", \"range\", \"range\", \"range\", \"rayburn\", \"recognition\", \"recognition\", \"recommendation\", \"recommendation\", \"recorded\", \"recorded\", \"recreation\", \"recreation\", \"recreation\", \"rehabilitation\", \"republican\", \"republicans\", \"research\", \"research\", \"research\", \"research\", \"research\", \"return\", \"return\", \"return\", \"return\", \"rhode\", \"rhode\", \"rico\", \"rico\", \"right\", \"right\", \"right\", \"right\", \"right\", \"robinson\", \"room\", \"room\", \"room\", \"said\", \"said\", \"said\", \"said\", \"said\", \"sales\", \"sales\", \"sales\", \"sales\", \"sat\", \"sat\", \"sat\", \"savings\", \"savings\", \"school\", \"school\", \"school\", \"school\", \"school\", \"schools\", \"schools\", \"schools\", \"schools\", \"schools\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"section\", \"section\", \"section\", \"section\", \"sectors\", \"service\", \"service\", \"service\", \"service\", \"service\", \"services\", \"services\", \"services\", \"services\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shares\", \"shares\", \"shares\", \"shelter\", \"shelter\", \"shipments\", \"small\", \"small\", \"small\", \"small\", \"small\", \"son\", \"son\", \"son\", \"son\", \"southern\", \"soviet\", \"soviet\", \"speaker\", \"speaker\", \"speaker\", \"st\", \"st\", \"stared\", \"state\", \"state\", \"state\", \"state\", \"state\", \"states\", \"states\", \"states\", \"states\", \"stations\", \"stations\", \"stations\", \"stockholders\", \"stockholders\", \"student\", \"student\", \"student\", \"student\", \"student\", \"students\", \"students\", \"students\", \"students\", \"students\", \"studio\", \"sun\", \"sun\", \"sun\", \"sure\", \"sure\", \"sure\", \"sure\", \"sweet\", \"system\", \"system\", \"system\", \"system\", \"system\", \"systems\", \"tax\", \"tax\", \"tax\", \"teachers\", \"teachers\", \"teachers\", \"technical\", \"technical\", \"tends\", \"thereof\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"title\", \"title\", \"title\", \"title\", \"tractor\", \"tractor\", \"treasury\", \"treasury\", \"trees\", \"trees\", \"troops\", \"trust\", \"trust\", \"trust\", \"trust\", \"trustees\", \"unions\", \"unions\", \"unions\", \"united\", \"united\", \"united\", \"united\", \"university\", \"university\", \"university\", \"university\", \"upstairs\", \"use\", \"use\", \"use\", \"use\", \"use\", \"utility\", \"utility\", \"ve\", \"ve\", \"ve\", \"ve\", \"vehicles\", \"vehicles\", \"vehicles\", \"vocational\", \"walls\", \"war\", \"war\", \"war\", \"war\", \"war\", \"wasn\", \"wasn\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"went\", \"went\", \"went\", \"west\", \"west\", \"west\", \"windows\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"yankees\", \"yards\", \"yellow\", \"yesterday\", \"yesterday\", \"yesterday\", \"yield\", \"yield\", \"york\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el897891402339169315366125029593\", ldavis_el897891402339169315366125029593_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el897891402339169315366125029593\", ldavis_el897891402339169315366125029593_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el897891402339169315366125029593\", ldavis_el897891402339169315366125029593_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d14c87",
   "metadata": {},
   "source": [
    "Q: What conclusions do you draw from the visualization above? Please address the principal component scatterplot and the salient terms graph.\n",
    "\n",
    "A: Within the salient terms graph, the estimated term frequency is always more gradual and accounts for a much smaller term frequency compared to the overall term frequency. However, in the fourth and fifth topic, we can see that the estimated term frequency starts to deviate and doesn't always correspond to the overall term frequency, which is more the case with the first three topics.\n",
    "\n",
    "With the principal component scatterplot, we can see that the first three topics' thirty most relevant terms account for about 75% of the total tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e23c2-fa86-4835-a721-cdd509565715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
